{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Specify, train and evaluate a PyTorch-based model using AbstractTorchFSMolModel\n",
    "\n",
    "We provide framework code so that few-shot models can be evaluated according to our benchmarking procedure using the `AbstractTorchFSMolModel` base class."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Setting up local details:\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# This should be the location of the checkout of the FS-Mol repository:\n",
    "FS_MOL_CHECKOUT_PATH = os.path.join(os.environ['HOME'], \"Projects\", \"FS-Mol\")\n",
    "FS_MOL_DATASET_PATH = os.path.join(os.environ['HOME'], \"Datasets\", \"FS-Mol\")\n",
    "\n",
    "os.chdir(FS_MOL_CHECKOUT_PATH)\n",
    "sys.path.insert(0, FS_MOL_CHECKOUT_PATH)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implementing a new `AbstractTorchFSMolModel`\n",
    "\n",
    "As example, we use `fs_models/models/gnn_multitask.py`, our implementation of a GNN model implementation, but repeat function definitions integrating with the larger framework in simplified form in this notebook.\n",
    "\n",
    "We need to implement five methods required by the `AbstractTorchFSMolModel` class:\n",
    "\n",
    "* `forward(self, batch: FSMolMultitaskBatch) -> torch.Tensor`:\n",
    "  This has to implement the core model, as usual.\n",
    "  It consumes a `FSMolMultitaskBatch` object, which is created by our batching pipeline, and extends the standard `FSMolBatch` by a mapping from each graph in the batch to a unique task ID.\n",
    "   \n",
    "  As is standard, our `GNNMultitaskModel` creates all needed sublayers in `__init__` and we now simply plug these together.\n",
    "  Concretely, we simply chain four components:\n",
    "  * Use `model.init_node_proj` to project the node features to the input for the GNN.\n",
    "  * Use `model.gnn` to implement the graph-based message passing.\n",
    "  * Use `model.readout` to compute a graph-level representation for all graphs in a minibatch.\n",
    "  * Use `model.tail_mlp` to compute per-task predictions for each graph in the minibatch.\n",
    "\n",
    "  The output of this method should be predictions that can be used to calculate a differentiable loss when combined with graph labels from the batch.\n",
    "\n",
    "* `get_model_state(self) -> ModelStateType` and `load_model_state(self, model_state: ModelStateType, load_task_specific_weights: bool, quiet: bool = False) -> None`:\n",
    "  These two methods should be sufficient to get the current state of the model (e.g., parameters of the model) and reset to it.\n",
    "  This is used to retrieve the best state found during the training loop and restoring it when evaluating on the test set.\n",
    "  `load_task_specific_weights` is used to signal that only generic parameters of a model should be loaded, e.g., when preparing to fine-tune on a new task.\n",
    "\n",
    "* `is_param_task_specific(self, param_name: str) -> bool`:\n",
    "  This method is used to determine which parameters are task-specific to implement different learning rates for different parts of the model during fine-tuning.\n",
    "\n",
    "* `build_from_model_file(...) -> AbstractTorchFSMolModel[BatchFeaturesType]`:\n",
    "  This is the core factory method creating a fresh model from scratch."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training an `AbstractTorchFSMolModel` model\n",
    "\n",
    "We provide a default training loop for implementations of `AbstractTorchFSMolModel`, implemented as `train_loop` in `fs_mol.models.abstract_torch_fsmol_model`. It is in particular useful for fine-tuning a pre-trained model, but can be used to train full models as well.\n",
    "\n",
    "To use it, we need to assemble a number of components:\n",
    "* An actual model, implementing `AbstractTorchFSMolModel`.\n",
    "* A data pipeline providing appropriate minibatches to the model.\n",
    "* A validation function which will evaluate the model on the validation tasks during training.\n",
    "\n",
    "We will show these steps in detail below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating the `GNNMultitask` model\n",
    "\n",
    "We first create the actual model - this is very much like any other PyTorch model, just requiring the interface discussed at the top of this notebook. We do not go into the details of the `GNNMultitask` model here."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "from fs_mol.models.gnn_multitask import (\n",
    "    GNNMultitaskConfig,\n",
    "    GNNMultitaskModel,\n",
    "    GNNConfig,\n",
    "    create_model,\n",
    ")\n",
    "from fs_mol.data.fsmol_dataset import FSMolDataset, DataFold\n",
    "\n",
    "fsmol_dataset = FSMolDataset.from_directory(FS_MOL_DATASET_PATH)\n",
    "\n",
    "# Set up an output directory in which to save a model\n",
    "out_dir = os.path.join(os.getcwd(), \"test\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Set up the model configuration that specifies a GNNMultitaskModel, using mostly default parameters.\n",
    "# Consult fs_mol/models/gnn_multitask.py for a full list.\n",
    "model_config = GNNMultitaskConfig(\n",
    "    num_tasks=fsmol_dataset.get_num_fold_tasks(DataFold.TRAIN),\n",
    "    gnn_config=GNNConfig(\n",
    "        type=\"PNA\",\n",
    "        hidden_dim=128,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# create an instance of a model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = create_model(model_config, device=device)\n",
    "\n",
    "print(f\"Num parameters {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Model:\\n{model}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num parameters 6357842\n",
      "Model:\n",
      "GNNMultitaskModel(\n",
      "  (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
      "  (gnn): GNN(\n",
      "    (gnn_blocks): ModuleList(\n",
      "      (0): GNNBlock(\n",
      "        (mp_layers): ModuleList(\n",
      "          (0): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (msg_out_projection): Linear(in_features=1536, out_features=128, bias=True)\n",
      "        (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (boom_layer): BOOMLayer(\n",
      "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (1): GNNBlock(\n",
      "        (mp_layers): ModuleList(\n",
      "          (0): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (msg_out_projection): Linear(in_features=1536, out_features=128, bias=True)\n",
      "        (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (boom_layer): BOOMLayer(\n",
      "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (2): GNNBlock(\n",
      "        (mp_layers): ModuleList(\n",
      "          (0): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (msg_out_projection): Linear(in_features=1536, out_features=128, bias=True)\n",
      "        (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (boom_layer): BOOMLayer(\n",
      "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (3): GNNBlock(\n",
      "        (mp_layers): ModuleList(\n",
      "          (0): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (msg_out_projection): Linear(in_features=1536, out_features=128, bias=True)\n",
      "        (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (boom_layer): BOOMLayer(\n",
      "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (4): GNNBlock(\n",
      "        (mp_layers): ModuleList(\n",
      "          (0): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (msg_out_projection): Linear(in_features=1536, out_features=128, bias=True)\n",
      "        (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (boom_layer): BOOMLayer(\n",
      "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (5): GNNBlock(\n",
      "        (mp_layers): ModuleList(\n",
      "          (0): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (msg_out_projection): Linear(in_features=1536, out_features=128, bias=True)\n",
      "        (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (boom_layer): BOOMLayer(\n",
      "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (6): GNNBlock(\n",
      "        (mp_layers): ModuleList(\n",
      "          (0): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (msg_out_projection): Linear(in_features=1536, out_features=128, bias=True)\n",
      "        (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (boom_layer): BOOMLayer(\n",
      "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (7): GNNBlock(\n",
      "        (mp_layers): ModuleList(\n",
      "          (0): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): RelationalMultiAggrMP(\n",
      "            (message_fns): ModuleList(\n",
      "              (0): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (1): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (2): MLP(\n",
      "                (_layers): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=96, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (msg_out_projection): Linear(in_features=1536, out_features=128, bias=True)\n",
      "        (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (boom_layer): BOOMLayer(\n",
      "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (readout): UnweightedGraphReadout(\n",
      "    (_combination_layer): Linear(in_features=1152, out_features=512, bias=False)\n",
      "  )\n",
      "  (tail_mlp): MLP(\n",
      "    (_layers): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=4938, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting up Batching\n",
    "\n",
    "To train the model, we first need to set up a data pipeline, which we can do using our existing batching infrastructure (see notebooks/dataset.ipynb for more details):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from fs_mol.data.multitask import MultitaskTaskSampleBatchIterable\n",
    "\n",
    "# note we need this dictionary to connect task numbers with names\n",
    "train_task_name_to_id = {\n",
    "    name: i for i, name in enumerate(fsmol_dataset.get_task_names(data_fold=DataFold.TRAIN))\n",
    "}\n",
    "\n",
    "train_data = MultitaskTaskSampleBatchIterable(\n",
    "    fsmol_dataset,\n",
    "    data_fold=DataFold.TRAIN,\n",
    "    task_name_to_id=train_task_name_to_id,\n",
    "    max_num_graphs=256,\n",
    ")\n",
    "print(f\"Have {len(train_task_name_to_id)} training tasks.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Have 4938 training tasks.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining a Validation Function\n",
    "\n",
    "Our generic `train_loop` takes a function to evaluate the current model to determine when to stop training (using early stopping) and to identify the best checkpoint.\n",
    "\n",
    "While there are many potential validation functions, a particularly obvious one is to evaluate how well the model performs on the validation tasks when fine-tuned on them, for which we provide a `eval_model_by_finetuning_on_task` function. Internally, that function will kick off another `train_loop` on a single task sample and report the results of the fine-tuned model on the test of that task sample."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import tempfile\n",
    "import numpy as np\n",
    "\n",
    "from fs_mol.data import FSMolTaskSample\n",
    "from fs_mol.data.multitask import get_multitask_inference_batcher\n",
    "from fs_mol.models.abstract_torch_fsmol_model import save_model, eval_model_by_finetuning_on_task\n",
    "from fs_mol.utils.metrics import BinaryEvalMetrics\n",
    "from fs_mol.utils.test_utils import eval_model\n",
    "\n",
    "def validate_by_finetuning_on_tasks(\n",
    "    model: GNNMultitaskModel,\n",
    "    seed: int = 0,\n",
    ") -> float:\n",
    "    with tempfile.TemporaryDirectory() as tempdir:\n",
    "        # First, store the current state of the model, so that we can just load it back in\n",
    "        # repeatedly as starting point during finetuning:\n",
    "        current_model_path = os.path.join(tempdir, \"cur_model.pt\")\n",
    "        save_model(current_model_path, model)\n",
    "\n",
    "        # Move model off GPU to make space for validation model:\n",
    "        model_device = model.device\n",
    "        model = model.to(torch.device(\"cpu\"))\n",
    "\n",
    "        def test_model_fn(\n",
    "            task_sample: FSMolTaskSample, temp_out_folder: str, seed: int\n",
    "        ) -> BinaryEvalMetrics:\n",
    "            return eval_model_by_finetuning_on_task(\n",
    "                current_model_path,\n",
    "                model_cls=GNNMultitaskModel,\n",
    "                task_sample=task_sample,\n",
    "                batcher=get_multitask_inference_batcher(max_num_graphs=256),\n",
    "                learning_rate=0.00005,\n",
    "                task_specific_learning_rate=0.0001,\n",
    "                quiet=True,\n",
    "                device=model_device,\n",
    "            )\n",
    "\n",
    "        task_to_results = eval_model(\n",
    "            test_model_fn=test_model_fn,\n",
    "            dataset=fsmol_dataset,\n",
    "            train_set_sample_sizes=[16],\n",
    "            num_samples=1,\n",
    "            valid_size_or_ratio=0.2,\n",
    "            test_size_or_ratio=128,\n",
    "            fold=DataFold.VALIDATION,\n",
    "            seed=seed,\n",
    "        )\n",
    "\n",
    "        model = model.to(model_device)\n",
    "\n",
    "        # Compute mean of average precisions per task:\n",
    "        return np.mean(\n",
    "            [\n",
    "                np.mean([task_result.avg_precision for task_result in task_results])\n",
    "                for task_results in task_to_results.values()\n",
    "            ]\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Running Training\n",
    "\n",
    "We are now ready to run training combining all of our components:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from fs_mol.models.abstract_torch_fsmol_model import (\n",
    "    train_loop,\n",
    "    create_optimizer,\n",
    ")\n",
    "\n",
    "validate_by_finetuning_on_tasks(model)\n",
    "\n",
    "# create a specific optimizer with learning rate for training\n",
    "optimizer, lr_scheduler = create_optimizer(model, lr=0.00005, task_specific_lr=0.0001)\n",
    "\n",
    "# run a training loop on the model for a single epoch - this will take ~15 minutes on a P100, or very long a CPU-only machine.\n",
    "best_valid_metric, best_model_state = train_loop(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    train_data=train_data,\n",
    "    valid_fn=validate_by_finetuning_on_tasks,\n",
    "    max_num_epochs=1,\n",
    ")\n",
    "\n",
    "# restore best model parameters:\n",
    "model.load_model_state(best_model_state, load_task_specific_weights=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "Finally, we can use the generic evaluation infrastructure (see notebooks/evaluation.ipynb) to evaluate the trained model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import tempfile\n",
    "from fs_mol.models.abstract_torch_fsmol_model import save_model\n",
    "\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    model_weights_file = os.path.join(temp_dir, \"model.pt\")\n",
    "    save_model(model_weights_file, model)\n",
    "\n",
    "    def test_model_fn(\n",
    "        task_sample: FSMolTaskSample, temp_out_folder: str, seed: int\n",
    "    ) -> BinaryEvalMetrics:\n",
    "        return eval_model_by_finetuning_on_task(\n",
    "            model_weights_file,\n",
    "            model_cls=GNNMultitaskModel,\n",
    "            task_sample=task_sample,\n",
    "            batcher=get_multitask_inference_batcher(max_num_graphs=256),\n",
    "            learning_rate=0.00005,\n",
    "            task_specific_learning_rate=0.0001,\n",
    "            seed=seed,\n",
    "            quiet=True,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    eval_results = eval_model(\n",
    "        test_model_fn=test_model_fn,\n",
    "        dataset=fsmol_dataset,\n",
    "        # Require a validation set so that fine-tuning can work\n",
    "        valid_size_or_ratio=0.2,\n",
    "        # Restrict number of samples to one per task:\n",
    "        train_set_sample_sizes=[16],\n",
    "        num_samples=1,\n",
    "    )\n",
    "\n",
    "eval_results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'CHEMBL1066254': [FSMolTaskSampleEvalResults(size=125, acc=0.624, balanced_acc=0.6189805327868853, f1=0.5154639175257733, prec=0.6944444444444444, recall=0.4098360655737705, roc_auc=0.6193647540983607, avg_precision=0.663094819639521, kappa=0.24026897711108242, task_name='CHEMBL1066254', seed=0, num_train=16, num_test=125, fraction_pos_train=0.5, fraction_pos_test=0.488)],\n",
       " 'CHEMBL1243970': [FSMolTaskSampleEvalResults(size=192, acc=0.578125, balanced_acc=0.578125, f1=0.5888324873096447, prec=0.5742574257425742, recall=0.6041666666666666, roc_auc=0.6119791666666666, avg_precision=0.5669025676717678, kappa=0.15625, task_name='CHEMBL1243970', seed=0, num_train=16, num_test=192, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL1243967': [FSMolTaskSampleEvalResults(size=192, acc=0.6041666666666666, balanced_acc=0.6041666666666667, f1=0.5957446808510638, prec=0.6086956521739131, recall=0.5833333333333334, roc_auc=0.6260850694444444, avg_precision=0.5825591442359164, kappa=0.20833333333333337, task_name='CHEMBL1243967', seed=0, num_train=16, num_test=192, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL1006005': [FSMolTaskSampleEvalResults(size=171, acc=0.5029239766081871, balanced_acc=0.5016420361247947, f1=0.45859872611464964, prec=0.4931506849315068, recall=0.42857142857142855, roc_auc=0.5046524356869185, avg_precision=0.5275903216708893, kappa=0.0032915038058012325, task_name='CHEMBL1006005', seed=0, num_train=16, num_test=171, fraction_pos_train=0.5, fraction_pos_test=0.49122807017543857)],\n",
       " 'CHEMBL1119333': [FSMolTaskSampleEvalResults(size=401, acc=0.5785536159600998, balanced_acc=0.5790920398009951, f1=0.6529774127310062, prec=0.554006968641115, recall=0.795, roc_auc=0.5352238805970149, avg_precision=0.5048954064509009, kappa=0.1580130952824681, task_name='CHEMBL1119333', seed=0, num_train=16, num_test=401, fraction_pos_train=0.5, fraction_pos_test=0.49875311720698257)],\n",
       " 'CHEMBL1613800': [FSMolTaskSampleEvalResults(size=1866, acc=0.5803858520900321, balanced_acc=0.5425982905982906, f1=0.4045627376425856, prec=0.4634146341463415, recall=0.358974358974359, roc_auc=0.5580962663067927, avg_precision=0.4741502862416363, kappa=0.08860461025424149, task_name='CHEMBL1613800', seed=0, num_train=16, num_test=1866, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.3971061093247588)],\n",
       " 'CHEMBL1613777': [FSMolTaskSampleEvalResults(size=3578, acc=0.5086640581330352, balanced_acc=0.5061641506697936, f1=0.4056795131845842, prec=0.5016722408026756, recall=0.340522133938706, roc_auc=0.5110386862646072, avg_precision=0.5026945856915436, kappa=0.012387463063391335, task_name='CHEMBL1613777', seed=0, num_train=16, num_test=3578, fraction_pos_train=0.5, fraction_pos_test=0.4924538848518726)],\n",
       " 'CHEMBL1613898': [FSMolTaskSampleEvalResults(size=151, acc=0.47019867549668876, balanced_acc=0.46964912280701754, f1=0.42028985507246375, prec=0.4603174603174603, recall=0.38666666666666666, roc_auc=0.4785964912280702, avg_precision=0.47715665024731324, kappa=-0.0607657182999648, task_name='CHEMBL1613898', seed=0, num_train=16, num_test=151, fraction_pos_train=0.5, fraction_pos_test=0.4966887417218543)],\n",
       " 'CHEMBL1613907': [FSMolTaskSampleEvalResults(size=133, acc=0.48120300751879697, balanced_acc=0.4845022624434389, f1=0.543046357615894, prec=0.47674418604651164, recall=0.6307692307692307, roc_auc=0.489027149321267, avg_precision=0.48760439308042547, kappa=-0.030776142873188972, task_name='CHEMBL1613907', seed=0, num_train=16, num_test=133, fraction_pos_train=0.5, fraction_pos_test=0.48872180451127817)],\n",
       " 'CHEMBL1613926': [FSMolTaskSampleEvalResults(size=119, acc=0.5966386554621849, balanced_acc=0.5984463276836158, f1=0.6666666666666666, prec=0.5647058823529412, recall=0.8135593220338984, roc_auc=0.6173728813559322, avg_precision=0.5946920319815819, kappa=0.19617224880382766, task_name='CHEMBL1613926', seed=0, num_train=16, num_test=119, fraction_pos_train=0.5, fraction_pos_test=0.4957983193277311)],\n",
       " 'CHEMBL1613949': [FSMolTaskSampleEvalResults(size=142, acc=0.5563380281690141, balanced_acc=0.5454246214614878, f1=0.4424778761061947, prec=0.390625, recall=0.5102040816326531, roc_auc=0.5626508667983322, avg_precision=0.41578412481014604, kappa=0.0847145488029466, task_name='CHEMBL1613949', seed=0, num_train=16, num_test=142, fraction_pos_train=0.3333333333333333, fraction_pos_test=0.34507042253521125)],\n",
       " 'CHEMBL1614466': [FSMolTaskSampleEvalResults(size=545, acc=0.5321100917431193, balanced_acc=0.5294496098289889, f1=0.47852760736196326, prec=0.4482758620689655, recall=0.5131578947368421, roc_auc=0.5529913110852842, avg_precision=0.4854776621923557, kappa=0.05772633891341039, task_name='CHEMBL1614466', seed=0, num_train=16, num_test=545, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.41834862385321103)],\n",
       " 'CHEMBL1614522': [FSMolTaskSampleEvalResults(size=742, acc=0.522911051212938, balanced_acc=0.5228421970357454, f1=0.5096952908587258, prec=0.5227272727272727, recall=0.4972972972972973, roc_auc=0.5504395524556815, avg_precision=0.5345931965432484, kappa=0.0456903692723547, task_name='CHEMBL1614522', seed=0, num_train=16, num_test=742, fraction_pos_train=0.5, fraction_pos_test=0.49865229110512127)],\n",
       " 'CHEMBL1614423': [FSMolTaskSampleEvalResults(size=513, acc=0.530214424951267, balanced_acc=0.46734397677793904, f1=0.24922118380062308, prec=0.31746031746031744, recall=0.20512820512820512, roc_auc=0.4684405741009514, avg_precision=0.3525499021125551, kappa=-0.07010983874737087, task_name='CHEMBL1614423', seed=0, num_train=16, num_test=513, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.38011695906432746)],\n",
       " 'CHEMBL1614153': [FSMolTaskSampleEvalResults(size=3072, acc=0.6022135416666666, balanced_acc=0.5060642255643604, f1=0.265625, prec=0.3480314960629921, recall=0.21477162293488825, roc_auc=0.5356558958105303, avg_precision=0.3581898087601525, kappa=0.013401917172714217, task_name='CHEMBL1614153', seed=0, num_train=16, num_test=3072, fraction_pos_train=0.3333333333333333, fraction_pos_test=0.3349609375)],\n",
       " 'CHEMBL1614027': [FSMolTaskSampleEvalResults(size=2977, acc=0.5220020154517971, balanced_acc=0.521684165107288, f1=0.4097884695147242, prec=0.534054054054054, recall=0.33243606998654107, roc_auc=0.5580183659155471, avg_precision=0.5503182693352552, kappa=0.0433957999271527, task_name='CHEMBL1614027', seed=0, num_train=16, num_test=2977, fraction_pos_train=0.5, fraction_pos_test=0.49916022841787033)],\n",
       " 'CHEMBL1614292': [FSMolTaskSampleEvalResults(size=1564, acc=0.5818414322250639, balanced_acc=0.5141389792180104, f1=0.32577319587628867, prec=0.3735224586288416, recall=0.28884826325411334, roc_auc=0.5226820468848588, avg_precision=0.3785093927458575, kappa=0.02984109158716819, task_name='CHEMBL1614292', seed=0, num_train=16, num_test=1564, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.34974424552429667)],\n",
       " 'CHEMBL1738633': [FSMolTaskSampleEvalResults(size=131, acc=0.6030534351145038, balanced_acc=0.6026806526806527, f1=0.5806451612903227, prec=0.6101694915254238, recall=0.5538461538461539, roc_auc=0.655011655011655, avg_precision=0.7030209262835, kappa=0.20550501516211794, task_name='CHEMBL1738633', seed=0, num_train=16, num_test=131, fraction_pos_train=0.5, fraction_pos_test=0.4961832061068702)],\n",
       " 'CHEMBL1738485': [FSMolTaskSampleEvalResults(size=286, acc=0.5314685314685315, balanced_acc=0.5314685314685315, f1=0.5347222222222222, prec=0.5310344827586206, recall=0.5384615384615384, roc_auc=0.5484375764096043, avg_precision=0.5687758986412513, kappa=0.06293706293706292, task_name='CHEMBL1738485', seed=0, num_train=16, num_test=286, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL1614433': [FSMolTaskSampleEvalResults(size=399, acc=0.5087719298245614, balanced_acc=0.5080010290712632, f1=0.46448087431693996, prec=0.43147208121827413, recall=0.5029585798816568, roc_auc=0.5171854900951891, avg_precision=0.43695188931700135, kappa=0.01565804047930719, task_name='CHEMBL1614433', seed=0, num_train=16, num_test=399, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.42355889724310775)],\n",
       " 'CHEMBL1794324': [FSMolTaskSampleEvalResults(size=2053, acc=0.5007306380905991, balanced_acc=0.4915257054708902, f1=0.2609949531362653, prec=0.4629156010230179, recall=0.1817269076305221, roc_auc=0.47441611289054036, avg_precision=0.47110643468980673, kappa=-0.017250955821677794, task_name='CHEMBL1794324', seed=0, num_train=16, num_test=2053, fraction_pos_train=0.5, fraction_pos_test=0.48514369215781783)],\n",
       " 'CHEMBL1738579': [FSMolTaskSampleEvalResults(size=198, acc=0.494949494949495, balanced_acc=0.49370199692780337, f1=0.46808510638297873, prec=0.4631578947368421, recall=0.4731182795698925, roc_auc=0.476804915514593, avg_precision=0.49425917668371205, kappa=-0.01258054617980986, task_name='CHEMBL1738579', seed=0, num_train=16, num_test=198, fraction_pos_train=0.5, fraction_pos_test=0.4696969696969697)],\n",
       " 'CHEMBL1614503': [FSMolTaskSampleEvalResults(size=118, acc=0.4830508474576271, balanced_acc=0.506006006006006, f1=0.4077669902912622, prec=0.3181818181818182, recall=0.5675675675675675, roc_auc=0.47180513847180516, avg_precision=0.31184806429074985, kappa=0.009903713892709831, task_name='CHEMBL1614503', seed=0, num_train=16, num_test=118, fraction_pos_train=0.3333333333333333, fraction_pos_test=0.3135593220338983)],\n",
       " 'CHEMBL1794504': [FSMolTaskSampleEvalResults(size=114, acc=0.47368421052631576, balanced_acc=0.4713669950738916, f1=0.5384615384615384, prec=0.4861111111111111, recall=0.603448275862069, roc_auc=0.4051724137931034, avg_precision=0.4594032019354855, kappa=-0.05751391465677158, task_name='CHEMBL1794504', seed=0, num_train=16, num_test=114, fraction_pos_train=0.5, fraction_pos_test=0.5087719298245614)],\n",
       " 'CHEMBL1963715': [FSMolTaskSampleEvalResults(size=875, acc=0.6, balanced_acc=0.5193077564637198, f1=0.26470588235294124, prec=0.4315068493150685, recall=0.19090909090909092, roc_auc=0.5380038921323325, avg_precision=0.40228530049840994, kappa=0.04338726807021942, task_name='CHEMBL1963715', seed=0, num_train=16, num_test=875, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.37714285714285717)],\n",
       " 'CHEMBL1614508': [FSMolTaskSampleEvalResults(size=153, acc=0.7777777777777778, balanced_acc=0.7716049382716049, f1=0.7384615384615385, prec=0.8275862068965517, recall=0.6666666666666666, roc_auc=0.7616598079561041, avg_precision=0.7979138840988311, kappa=0.5491419656786272, task_name='CHEMBL1614508', seed=0, num_train=16, num_test=153, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.47058823529411764)],\n",
       " 'CHEMBL1963756': [FSMolTaskSampleEvalResults(size=746, acc=0.5227882037533512, balanced_acc=0.49435779274488956, f1=0.35971223021582743, prec=0.4098360655737705, recall=0.32051282051282054, roc_auc=0.4946310410020087, avg_precision=0.41109573914004593, kappa=-0.011641017827213052, task_name='CHEMBL1963756', seed=0, num_train=16, num_test=746, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.41823056300268097)],\n",
       " 'CHEMBL1794519': [FSMolTaskSampleEvalResults(size=140, acc=0.6142857142857143, balanced_acc=0.6142857142857143, f1=0.6493506493506493, prec=0.5952380952380952, recall=0.7142857142857143, roc_auc=0.6951020408163265, avg_precision=0.7116578609075404, kappa=0.22857142857142854, task_name='CHEMBL1794519', seed=0, num_train=16, num_test=140, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL1737951': [FSMolTaskSampleEvalResults(size=177, acc=0.6779661016949152, balanced_acc=0.691031941031941, f1=0.6322580645161291, prec=0.550561797752809, recall=0.7424242424242424, roc_auc=0.6938984438984439, avg_precision=0.49180865127833684, kappa=0.3568559954102123, task_name='CHEMBL1737951', seed=0, num_train=16, num_test=177, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.3728813559322034)],\n",
       " 'CHEMBL1963701': [FSMolTaskSampleEvalResults(size=904, acc=0.5232300884955752, balanced_acc=0.5232300884955752, f1=0.5827686350435624, prec=0.5180722891566265, recall=0.665929203539823, roc_auc=0.5362866121074477, avg_precision=0.5169628933894785, kappa=0.04646017699115046, task_name='CHEMBL1963701', seed=0, num_train=16, num_test=904, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL1963799': [FSMolTaskSampleEvalResults(size=345, acc=0.5884057971014492, balanced_acc=0.5164462049939874, f1=0.26804123711340205, prec=0.43333333333333335, recall=0.19402985074626866, roc_auc=0.5480476763103912, avg_precision=0.42555629167941034, kappa=0.036578171091445455, task_name='CHEMBL1963799', seed=0, num_train=16, num_test=345, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.3884057971014493)],\n",
       " 'CHEMBL1738079': [FSMolTaskSampleEvalResults(size=216, acc=0.5416666666666666, balanced_acc=0.53989703989704, f1=0.5025125628140702, prec=0.5319148936170213, recall=0.47619047619047616, roc_auc=0.49764049764049767, avg_precision=0.49929527230878323, kappa=0.08002065049044915, task_name='CHEMBL1738079', seed=0, num_train=16, num_test=216, fraction_pos_train=0.5, fraction_pos_test=0.4861111111111111)],\n",
       " 'CHEMBL1963824': [FSMolTaskSampleEvalResults(size=407, acc=0.5282555282555282, balanced_acc=0.5040540540540541, f1=0.31428571428571433, prec=0.4631578947368421, recall=0.23783783783783785, roc_auc=0.4971025079133187, avg_precision=0.49242899813873997, kappa=0.008450704225352101, task_name='CHEMBL1963824', seed=0, num_train=16, num_test=407, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.45454545454545453)],\n",
       " 'CHEMBL1963705': [FSMolTaskSampleEvalResults(size=675, acc=0.52, balanced_acc=0.4895779028169774, f1=0.33877551020408164, prec=0.4068627450980392, recall=0.2902097902097902, roc_auc=0.530803386844518, avg_precision=0.4176800682345799, kappa=-0.021666619951229205, task_name='CHEMBL1963705', seed=0, num_train=16, num_test=675, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.4237037037037037)],\n",
       " 'CHEMBL1738362': [FSMolTaskSampleEvalResults(size=123, acc=0.6910569105691057, balanced_acc=0.6455108359133126, f1=0.5128205128205129, prec=0.5, recall=0.5263157894736842, roc_auc=0.778328173374613, avg_precision=0.5972701249926962, kappa=0.2868477265791882, task_name='CHEMBL1738362', seed=0, num_train=16, num_test=123, fraction_pos_train=0.3333333333333333, fraction_pos_test=0.3089430894308943)],\n",
       " 'CHEMBL1963741': [FSMolTaskSampleEvalResults(size=911, acc=0.5225027442371021, balanced_acc=0.4941897810218978, f1=0.27860696517412936, prec=0.4375, recall=0.20437956204379562, roc_auc=0.4748272506082726, avg_precision=0.43454142319875266, kappa=-0.012198953280767588, task_name='CHEMBL1963741', seed=0, num_train=16, num_test=911, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.45115257958287597)],\n",
       " 'CHEMBL1963827': [FSMolTaskSampleEvalResults(size=597, acc=0.49748743718592964, balanced_acc=0.49955665798689053, f1=0.5956873315363881, prec=0.49551569506726456, recall=0.7466216216216216, roc_auc=0.4996520606985724, avg_precision=0.49143572578597583, kappa=-0.0008829676655006669, task_name='CHEMBL1963827', seed=0, num_train=16, num_test=597, fraction_pos_train=0.5, fraction_pos_test=0.49581239530988275)],\n",
       " 'CHEMBL1738395': [FSMolTaskSampleEvalResults(size=159, acc=0.5471698113207547, balanced_acc=0.5477056962025317, f1=0.5813953488372092, prec=0.5376344086021505, recall=0.6329113924050633, roc_auc=0.546993670886076, avg_precision=0.5388871557820992, kappa=0.09530583214793742, task_name='CHEMBL1738395', seed=0, num_train=16, num_test=159, fraction_pos_train=0.5, fraction_pos_test=0.4968553459119497)],\n",
       " 'CHEMBL1963969': [FSMolTaskSampleEvalResults(size=224, acc=0.44642857142857145, balanced_acc=0.4464285714285714, f1=0.45132743362831856, prec=0.4473684210526316, recall=0.45535714285714285, roc_auc=0.4551977040816326, avg_precision=0.48098144566780265, kappa=-0.1071428571428572, task_name='CHEMBL1963969', seed=0, num_train=16, num_test=224, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL1963773': [FSMolTaskSampleEvalResults(size=507, acc=0.5483234714003945, balanced_acc=0.5129916853213943, f1=0.35492957746478876, prec=0.4405594405594406, recall=0.2971698113207547, roc_auc=0.5287016309561879, avg_precision=0.43103867586315475, kappa=0.027230149221217692, task_name='CHEMBL1963773', seed=0, num_train=16, num_test=507, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.4181459566074951)],\n",
       " 'CHEMBL1738502': [FSMolTaskSampleEvalResults(size=688, acc=0.5537790697674418, balanced_acc=0.5462050179742801, f1=0.4508050089445439, prec=0.39747634069400634, recall=0.5206611570247934, roc_auc=0.5800550346514471, avg_precision=0.44833897921886035, kappa=0.0862937135540136, task_name='CHEMBL1738502', seed=0, num_train=16, num_test=688, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.35174418604651164)],\n",
       " 'CHEMBL1963819': [FSMolTaskSampleEvalResults(size=715, acc=0.6223776223776224, balanced_acc=0.5117849462365591, f1=0.2105263157894737, prec=0.391304347826087, recall=0.144, roc_auc=0.569578494623656, avg_precision=0.3903833325354217, kappa=0.02760288117664844, task_name='CHEMBL1963819', seed=0, num_train=16, num_test=715, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.34965034965034963)],\n",
       " 'CHEMBL1964101': [FSMolTaskSampleEvalResults(size=978, acc=0.5633946830265849, balanced_acc=0.5633405821344931, f1=0.5509989484752891, prec=0.5658747300215983, recall=0.5368852459016393, roc_auc=0.6022896453663433, avg_precision=0.5494568420959822, kappa=0.12669441017168914, task_name='CHEMBL1964101', seed=0, num_train=16, num_test=978, fraction_pos_train=0.5, fraction_pos_test=0.49897750511247446)],\n",
       " 'CHEMBL1738573': [FSMolTaskSampleEvalResults(size=1450, acc=0.5089655172413793, balanced_acc=0.5089655172413793, f1=0.4795321637426901, prec=0.5101088646967341, recall=0.45241379310344826, roc_auc=0.5105445897740785, avg_precision=0.5035959251622992, kappa=0.017931034482758568, task_name='CHEMBL1738573', seed=0, num_train=16, num_test=1450, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL2218957': [FSMolTaskSampleEvalResults(size=141, acc=0.5390070921985816, balanced_acc=0.538430583501006, f1=0.49612403100775193, prec=0.5423728813559322, recall=0.45714285714285713, roc_auc=0.5859154929577466, avg_precision=0.6552516711986682, kappa=0.07694631886393388, task_name='CHEMBL2218957', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL1963825': [FSMolTaskSampleEvalResults(size=390, acc=0.5076923076923077, balanced_acc=0.538792074480783, f1=0.6175298804780877, prec=0.47692307692307695, recall=0.8757062146892656, roc_auc=0.6379671626747301, avg_precision=0.597142379556833, kappa=0.07246376811594202, task_name='CHEMBL1963825', seed=0, num_train=16, num_test=390, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.45384615384615384)],\n",
       " 'CHEMBL1794557': [FSMolTaskSampleEvalResults(size=836, acc=0.5, balanced_acc=0.5, f1=0.3976945244956772, prec=0.5, recall=0.33014354066985646, roc_auc=0.507191341773311, avg_precision=0.5050169285579802, kappa=0.0, task_name='CHEMBL1794557', seed=0, num_train=16, num_test=836, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL1963910': [FSMolTaskSampleEvalResults(size=184, acc=0.4891304347826087, balanced_acc=0.4891304347826087, f1=0.4946236559139785, prec=0.48936170212765956, recall=0.5, roc_auc=0.49586483931947073, avg_precision=0.5286945212787337, kappa=-0.021739130434782705, task_name='CHEMBL1963910', seed=0, num_train=16, num_test=184, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL2218989': [FSMolTaskSampleEvalResults(size=141, acc=0.6453900709219859, balanced_acc=0.6456740442655935, f1=0.6575342465753424, prec=0.631578947368421, recall=0.6857142857142857, roc_auc=0.7237424547283703, avg_precision=0.6997708438011996, kappa=0.2911723305851599, task_name='CHEMBL2218989', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL1963721': [FSMolTaskSampleEvalResults(size=331, acc=0.48036253776435045, balanced_acc=0.4734886231523003, f1=0.362962962962963, prec=0.30246913580246915, recall=0.4537037037037037, roc_auc=0.48376515528981895, avg_precision=0.3081421250316857, kappa=-0.04696752363088019, task_name='CHEMBL1963721', seed=0, num_train=16, num_test=331, fraction_pos_train=0.3333333333333333, fraction_pos_test=0.32628398791540786)],\n",
       " 'CHEMBL2219028': [FSMolTaskSampleEvalResults(size=141, acc=0.5035460992907801, balanced_acc=0.504225352112676, f1=0.5454545454545454, prec=0.5, recall=0.6, roc_auc=0.4607645875251509, avg_precision=0.4914057149155369, kappa=0.008438818565400963, task_name='CHEMBL2219028', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL1964005': [FSMolTaskSampleEvalResults(size=149, acc=0.610738255033557, balanced_acc=0.6098198198198198, f1=0.546875, prec=0.6481481481481481, recall=0.47297297297297297, roc_auc=0.6443243243243244, avg_precision=0.6596363818881097, kappa=0.2200361010830324, task_name='CHEMBL1964005', seed=0, num_train=16, num_test=149, fraction_pos_train=0.5, fraction_pos_test=0.4966442953020134)],\n",
       " 'CHEMBL1963723': [FSMolTaskSampleEvalResults(size=840, acc=0.5083333333333333, balanced_acc=0.5191794596385784, f1=0.5436464088397791, prec=0.47126436781609193, recall=0.6422976501305483, roc_auc=0.5334626437602482, avg_precision=0.4938144422836695, kappa=0.037263978154450705, task_name='CHEMBL1963723', seed=0, num_train=16, num_test=840, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.45595238095238094)],\n",
       " 'CHEMBL2218946': [FSMolTaskSampleEvalResults(size=141, acc=0.5673758865248227, balanced_acc=0.5688405797101449, f1=0.5906040268456376, prec=0.55, recall=0.6376811594202898, roc_auc=0.623389694041868, avg_precision=0.6028500349207598, kappa=0.13722539873608186, task_name='CHEMBL2218946', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48936170212765956)],\n",
       " 'CHEMBL2219043': [FSMolTaskSampleEvalResults(size=141, acc=0.475177304964539, balanced_acc=0.47323943661971835, f1=0.27450980392156865, prec=0.4375, recall=0.2, roc_auc=0.46720321931589537, avg_precision=0.46723644769161343, kappa=-0.05372651989497079, task_name='CHEMBL2219043', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL1963731': [FSMolTaskSampleEvalResults(size=624, acc=0.5192307692307693, balanced_acc=0.4536151616113539, f1=0.20634920634920634, prec=0.2867647058823529, recall=0.16115702479338842, roc_auc=0.5136298732205443, avg_precision=0.3648108147546619, kappa=-0.10086563793752368, task_name='CHEMBL1963731', seed=0, num_train=16, num_test=624, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.38782051282051283)],\n",
       " 'CHEMBL2219050': [FSMolTaskSampleEvalResults(size=141, acc=0.5390070921985816, balanced_acc=0.5382293762575453, f1=0.4799999999999999, prec=0.5454545454545454, recall=0.42857142857142855, roc_auc=0.5028169014084507, avg_precision=0.5340262104465263, kappa=0.07657430730478587, task_name='CHEMBL2219050', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2218959': [FSMolTaskSampleEvalResults(size=141, acc=0.574468085106383, balanced_acc=0.5738430583501006, f1=0.53125, prec=0.5862068965517241, recall=0.4857142857142857, roc_auc=0.6400402414486921, avg_precision=0.6365965349361531, kappa=0.1478646253021756, task_name='CHEMBL2218959', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL1963810': [FSMolTaskSampleEvalResults(size=654, acc=0.47553516819571867, balanced_acc=0.47454698693636743, f1=0.4512, prec=0.45483870967741935, recall=0.44761904761904764, roc_auc=0.45023645643114674, avg_precision=0.43910958741381945, kappa=-0.05093464511595225, task_name='CHEMBL1963810', seed=0, num_train=16, num_test=654, fraction_pos_train=0.5, fraction_pos_test=0.481651376146789)],\n",
       " 'CHEMBL2219026': [FSMolTaskSampleEvalResults(size=141, acc=0.5035460992907801, balanced_acc=0.506969696969697, f1=0.5138888888888888, prec=0.47435897435897434, recall=0.5606060606060606, roc_auc=0.48262626262626257, avg_precision=0.4690596013415197, kappa=0.013788968824940073, task_name='CHEMBL2219026', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.46808510638297873)],\n",
       " 'CHEMBL2219070': [FSMolTaskSampleEvalResults(size=141, acc=0.5390070921985816, balanced_acc=0.5403388463089955, f1=0.5390070921985815, prec=0.5135135135135135, recall=0.5671641791044776, roc_auc=0.5514320290439694, avg_precision=0.5112003640217107, kappa=0.08028098344204726, task_name='CHEMBL2219070', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.475177304964539)],\n",
       " 'CHEMBL1963818': [FSMolTaskSampleEvalResults(size=594, acc=0.5016835016835017, balanced_acc=0.505480534652785, f1=0.49488054607508525, prec=0.45454545454545453, recall=0.5430711610486891, roc_auc=0.49878019448166855, avg_precision=0.4379028627039234, kappa=0.01076865948756034, task_name='CHEMBL1963818', seed=0, num_train=16, num_test=594, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.4494949494949495)],\n",
       " 'CHEMBL2219093': [FSMolTaskSampleEvalResults(size=141, acc=0.6666666666666666, balanced_acc=0.6634770346494763, f1=0.6239999999999999, prec=0.6842105263157895, recall=0.5735294117647058, roc_auc=0.7066881547139403, avg_precision=0.6805540186112812, kappa=0.32877544819203885, task_name='CHEMBL2219093', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48226950354609927)],\n",
       " 'CHEMBL2219040': [FSMolTaskSampleEvalResults(size=141, acc=0.6524822695035462, balanced_acc=0.651810865191147, f1=0.6141732283464566, prec=0.6842105263157895, recall=0.5571428571428572, roc_auc=0.6883299798792757, avg_precision=0.6953379082599167, kappa=0.30401934119069196, task_name='CHEMBL2219040', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL1963831': [FSMolTaskSampleEvalResults(size=374, acc=0.5962566844919787, balanced_acc=0.5425538322541786, f1=0.3682008368200837, prec=0.46808510638297873, recall=0.30344827586206896, roc_auc=0.5755157355819907, avg_precision=0.4451291462963261, kappa=0.09097640279432129, task_name='CHEMBL1963831', seed=0, num_train=16, num_test=374, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.3877005347593583)],\n",
       " 'CHEMBL2219049': [FSMolTaskSampleEvalResults(size=141, acc=0.49645390070921985, balanced_acc=0.4958752515090543, f1=0.4496124031007752, prec=0.4915254237288136, recall=0.4142857142857143, roc_auc=0.47303822937625756, avg_precision=0.4908248402263641, kappa=-0.008258636317856949, task_name='CHEMBL2219049', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219102': [FSMolTaskSampleEvalResults(size=141, acc=0.5673758865248227, balanced_acc=0.5799755799755799, f1=0.5906040268456376, prec=0.5116279069767442, recall=0.6984126984126984, roc_auc=0.6298331298331299, avg_precision=0.5593149643710481, kappa=0.15452668829253902, task_name='CHEMBL2219102', seed=0, num_train=16, num_test=141, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.44680851063829785)],\n",
       " 'CHEMBL1963838': [FSMolTaskSampleEvalResults(size=224, acc=0.5535714285714286, balanced_acc=0.5535714285714286, f1=0.5098039215686274, prec=0.5652173913043478, recall=0.4642857142857143, roc_auc=0.5537308673469388, avg_precision=0.5287478236705986, kappa=0.1071428571428571, task_name='CHEMBL1963838', seed=0, num_train=16, num_test=224, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL2219120': [FSMolTaskSampleEvalResults(size=141, acc=0.5531914893617021, balanced_acc=0.5501207729468599, f1=0.4705882352941177, prec=0.56, recall=0.4057971014492754, roc_auc=0.5742753623188406, avg_precision=0.5176230438804833, kappa=0.1008199210446401, task_name='CHEMBL2219120', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48936170212765956)],\n",
       " 'CHEMBL2219059': [FSMolTaskSampleEvalResults(size=141, acc=0.475177304964539, balanced_acc=0.4744466800804829, f1=0.41269841269841273, prec=0.4642857142857143, recall=0.37142857142857144, roc_auc=0.4486921529175051, avg_precision=0.467067953795099, kappa=-0.051178722546846744, task_name='CHEMBL2219059', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL1964106': [FSMolTaskSampleEvalResults(size=300, acc=0.5366666666666666, balanced_acc=0.48262032085561496, f1=0.3152709359605911, prec=0.31683168316831684, recall=0.3137254901960784, roc_auc=0.47895622895622897, avg_precision=0.3330173073191198, kappa=-0.034842167957117365, task_name='CHEMBL1964106', seed=0, num_train=16, num_test=300, fraction_pos_train=0.3333333333333333, fraction_pos_test=0.34)],\n",
       " 'CHEMBL2219088': [FSMolTaskSampleEvalResults(size=141, acc=0.5177304964539007, balanced_acc=0.5172032193158953, f1=0.47692307692307695, prec=0.5166666666666667, recall=0.44285714285714284, roc_auc=0.5476861167002012, avg_precision=0.5519336924790194, kappa=0.03444108761329301, task_name='CHEMBL2219088', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219150': [FSMolTaskSampleEvalResults(size=141, acc=0.5815602836879432, balanced_acc=0.5818913480885312, f1=0.5986394557823129, prec=0.5714285714285714, recall=0.6285714285714286, roc_auc=0.6221327967806841, avg_precision=0.6383915236901612, kappa=0.16366743741831713, task_name='CHEMBL2219150', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL1964115': [FSMolTaskSampleEvalResults(size=324, acc=0.5, balanced_acc=0.4906498363721365, f1=0.42142857142857143, prec=0.4154929577464789, recall=0.427536231884058, roc_auc=0.529842605578931, avg_precision=0.4458404668683027, kappa=-0.01863064741499776, task_name='CHEMBL1964115', seed=0, num_train=16, num_test=324, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.42592592592592593)],\n",
       " 'CHEMBL2219174': [FSMolTaskSampleEvalResults(size=141, acc=0.49645390070921985, balanced_acc=0.49738430583501003, f1=0.5534591194968553, prec=0.4943820224719101, recall=0.6285714285714286, roc_auc=0.5523138832997988, avg_precision=0.5775585820821676, kappa=-0.005221407771864639, task_name='CHEMBL2219174', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219098': [FSMolTaskSampleEvalResults(size=141, acc=0.5886524822695035, balanced_acc=0.5876361436062929, f1=0.5671641791044776, prec=0.5671641791044776, recall=0.5671641791044776, roc_auc=0.5982250907624042, avg_precision=0.5401861547052211, kappa=0.1752722872125857, task_name='CHEMBL2219098', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.475177304964539)],\n",
       " 'CHEMBL2218994': [FSMolTaskSampleEvalResults(size=141, acc=0.524822695035461, balanced_acc=0.5211778943122227, f1=0.4724409448818898, prec=0.5, recall=0.44776119402985076, roc_auc=0.4774102460669625, avg_precision=0.4554329736938008, kappa=0.042566129522651264, task_name='CHEMBL2218994', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.475177304964539)],\n",
       " 'CHEMBL2219115': [FSMolTaskSampleEvalResults(size=141, acc=0.524822695035461, balanced_acc=0.5214544721998389, f1=0.464, prec=0.5087719298245614, recall=0.4264705882352941, roc_auc=0.5412973408541498, avg_precision=0.5408827503550344, kappa=0.043147979337587405, task_name='CHEMBL2219115', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48226950354609927)],\n",
       " 'CHEMBL2219180': [FSMolTaskSampleEvalResults(size=141, acc=0.48936170212765956, balanced_acc=0.4870169082125604, f1=0.41935483870967744, prec=0.4727272727272727, recall=0.37681159420289856, roc_auc=0.47987117552334946, avg_precision=0.5201358787494091, kappa=-0.026076409945421597, task_name='CHEMBL2219180', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48936170212765956)],\n",
       " 'CHEMBL2219020': [FSMolTaskSampleEvalResults(size=141, acc=0.46099290780141844, balanced_acc=0.45945674044265594, f1=0.30909090909090914, prec=0.425, recall=0.24285714285714285, roc_auc=0.5136820925553319, avg_precision=0.5040181131651669, kappa=-0.08133198789101925, task_name='CHEMBL2219020', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219198': [FSMolTaskSampleEvalResults(size=141, acc=0.5531914893617021, balanced_acc=0.5522132796780684, f1=0.47933884297520657, prec=0.5686274509803921, recall=0.4142857142857143, roc_auc=0.575251509054326, avg_precision=0.6193170101749512, kappa=0.10462654974296937, task_name='CHEMBL2219198', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219146': [FSMolTaskSampleEvalResults(size=141, acc=0.5035460992907801, balanced_acc=0.505533199195171, f1=0.6111111111111112, prec=0.5, recall=0.7857142857142857, roc_auc=0.48873239436619725, avg_precision=0.5196654593888995, kappa=0.01102204408817642, task_name='CHEMBL2219146', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219045': [FSMolTaskSampleEvalResults(size=141, acc=0.46808510638297873, balanced_acc=0.4716183574879227, f1=0.5398773006134969, prec=0.46808510638297873, recall=0.6376811594202898, roc_auc=0.4965780998389694, avg_precision=0.5544086929468885, kappa=-0.05633802816901401, task_name='CHEMBL2219045', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48936170212765956)],\n",
       " 'CHEMBL2219164': [FSMolTaskSampleEvalResults(size=141, acc=0.5319148936170213, balanced_acc=0.5303822937625755, f1=0.4, prec=0.55, recall=0.3142857142857143, roc_auc=0.4702213279678068, avg_precision=0.523517630794755, kappa=0.06094853683148327, task_name='CHEMBL2219164', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219203': [FSMolTaskSampleEvalResults(size=141, acc=0.6382978723404256, balanced_acc=0.6391690197660347, f1=0.6330935251798562, prec=0.6111111111111112, recall=0.6567164179104478, roc_auc=0.6690197660346914, avg_precision=0.6002876789061327, kappa=0.277359059391016, task_name='CHEMBL2219203', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.475177304964539)],\n",
       " 'CHEMBL2219047': [FSMolTaskSampleEvalResults(size=141, acc=0.5106382978723404, balanced_acc=0.509076240419524, f1=0.48120300751879697, prec=0.48484848484848486, recall=0.47761194029850745, roc_auc=0.4679306171843485, avg_precision=0.4746096768249531, kappa=0.01816530426884644, task_name='CHEMBL2219047', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.475177304964539)],\n",
       " 'CHEMBL2219225': [FSMolTaskSampleEvalResults(size=141, acc=0.5035460992907801, balanced_acc=0.5022132796780684, f1=0.38596491228070173, prec=0.5, recall=0.3142857142857143, roc_auc=0.5189134808853119, avg_precision=0.5046498922620851, kappa=0.004438168246923446, task_name='CHEMBL2219225', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219175': [FSMolTaskSampleEvalResults(size=141, acc=0.5957446808510638, balanced_acc=0.6054545454545455, f1=0.6369426751592356, prec=0.5494505494505495, recall=0.7575757575757576, roc_auc=0.5965656565656565, avg_precision=0.5502642385711167, kappa=0.2062222222222223, task_name='CHEMBL2219175', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.46808510638297873)],\n",
       " 'CHEMBL2219075': [FSMolTaskSampleEvalResults(size=141, acc=0.6170212765957447, balanced_acc=0.617102615694165, f1=0.619718309859155, prec=0.6111111111111112, recall=0.6285714285714286, roc_auc=0.6201207243460765, avg_precision=0.6048738966995348, kappa=0.23415811707905865, task_name='CHEMBL2219075', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219194': [FSMolTaskSampleEvalResults(size=141, acc=0.5815602836879432, balanced_acc=0.5886446147640177, f1=0.6242038216560509, prec=0.5444444444444444, recall=0.7313432835820896, roc_auc=0.635941912061315, avg_precision=0.5680950033519325, kappa=0.1744566835367668, task_name='CHEMBL2219194', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.475177304964539)],\n",
       " 'CHEMBL2219236': [FSMolTaskSampleEvalResults(size=141, acc=0.6170212765957447, balanced_acc=0.6169014084507043, f1=0.608695652173913, prec=0.6176470588235294, recall=0.6, roc_auc=0.682897384305835, avg_precision=0.6809811829330142, kappa=0.23384986918897155, task_name='CHEMBL2219236', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219076': [FSMolTaskSampleEvalResults(size=141, acc=0.574468085106383, balanced_acc=0.5763888888888888, f1=0.6052631578947367, prec=0.5542168674698795, recall=0.6666666666666666, roc_auc=0.586755233494364, avg_precision=0.5210731697904236, kappa=0.15213469633193033, task_name='CHEMBL2219076', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48936170212765956)],\n",
       " 'CHEMBL2219267': [FSMolTaskSampleEvalResults(size=141, acc=0.5673758865248227, balanced_acc=0.5667002012072435, f1=0.5196850393700787, prec=0.5789473684210527, recall=0.4714285714285714, roc_auc=0.5724346076458753, avg_precision=0.5707890369552426, kappa=0.13357509821698388, task_name='CHEMBL2219267', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219202': [FSMolTaskSampleEvalResults(size=141, acc=0.46099290780141844, balanced_acc=0.46167002012072433, f1=0.5064935064935066, prec=0.4642857142857143, recall=0.5571428571428572, roc_auc=0.48611670020120723, avg_precision=0.5054704310038609, kappa=-0.07655213984327891, task_name='CHEMBL2219202', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219104': [FSMolTaskSampleEvalResults(size=141, acc=0.5177304964539007, balanced_acc=0.5251813053988719, f1=0.5952380952380952, prec=0.5, recall=0.7352941176470589, roc_auc=0.5130942788074133, avg_precision=0.5171995609887041, kappa=0.049563838223632084, task_name='CHEMBL2219104', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48226950354609927)],\n",
       " 'CHEMBL2219223': [FSMolTaskSampleEvalResults(size=141, acc=0.5035460992907801, balanced_acc=0.4973811442385173, f1=0.3859649122807018, prec=0.4782608695652174, recall=0.3235294117647059, roc_auc=0.5366639806607575, avg_precision=0.5431584279750292, kappa=-0.005296394377673597, task_name='CHEMBL2219223', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48226950354609927)],\n",
       " 'CHEMBL2219272': [FSMolTaskSampleEvalResults(size=141, acc=0.46099290780141844, balanced_acc=0.460261569416499, f1=0.39682539682539686, prec=0.44642857142857145, recall=0.35714285714285715, roc_auc=0.45070422535211263, avg_precision=0.46458847640062495, kappa=-0.07958895829135604, task_name='CHEMBL2219272', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219113': [FSMolTaskSampleEvalResults(size=141, acc=0.5106382978723404, balanced_acc=0.511569416498994, f1=0.5660377358490566, prec=0.5056179775280899, recall=0.6428571428571429, roc_auc=0.6014084507042253, avg_precision=0.6768038044888094, kappa=0.023094688221709125, task_name='CHEMBL2219113', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219297': [FSMolTaskSampleEvalResults(size=141, acc=0.5957446808510638, balanced_acc=0.5901573215006051, f1=0.5289256198347108, prec=0.5925925925925926, recall=0.47761194029850745, roc_auc=0.5855183541750706, avg_precision=0.5138332954262459, kappa=0.1819847328244275, task_name='CHEMBL2219297', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.475177304964539)],\n",
       " 'CHEMBL2219232': [FSMolTaskSampleEvalResults(size=141, acc=0.475177304964539, balanced_acc=0.47454728370221333, f1=0.42187500000000006, prec=0.46551724137931033, recall=0.38571428571428573, roc_auc=0.5048289738430584, avg_precision=0.49597017272686295, kappa=-0.05096696212731677, task_name='CHEMBL2219232', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219159': [FSMolTaskSampleEvalResults(size=141, acc=0.5035460992907801, balanced_acc=0.49788477034649475, f1=0.39655172413793105, prec=0.4791666666666667, recall=0.3382352941176471, roc_auc=0.5, avg_precision=0.48237115964953214, kappa=-0.004273504273504258, task_name='CHEMBL2219159', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48226950354609927)],\n",
       " 'CHEMBL2219252': [FSMolTaskSampleEvalResults(size=141, acc=0.5177304964539007, balanced_acc=0.5195171026156942, f1=0.6136363636363636, prec=0.5094339622641509, recall=0.7714285714285715, roc_auc=0.4855130784708249, avg_precision=0.5440317065347546, kappa=0.03889334402566158, task_name='CHEMBL2219252', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219308': [FSMolTaskSampleEvalResults(size=141, acc=0.475177304964539, balanced_acc=0.4758551307847082, f1=0.5194805194805195, prec=0.47619047619047616, recall=0.5714285714285714, roc_auc=0.4275653923541247, avg_precision=0.4369565532196301, kappa=-0.048221820373719027, task_name='CHEMBL2219308', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219161': [FSMolTaskSampleEvalResults(size=141, acc=0.5035460992907801, balanced_acc=0.5037223340040241, f1=0.513888888888889, prec=0.5, recall=0.5285714285714286, roc_auc=0.4776659959758552, avg_precision=0.4702326225614391, kappa=0.007441673370876978, task_name='CHEMBL2219161', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219352': [FSMolTaskSampleEvalResults(size=141, acc=0.46808510638297873, balanced_acc=0.4596091861402095, f1=0.28571428571428575, prec=0.40540540540540543, recall=0.22058823529411764, roc_auc=0.46837228041901696, avg_precision=0.4449788079006928, kappa=-0.08206282615368887, task_name='CHEMBL2219352', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48226950354609927)],\n",
       " 'CHEMBL2219270': [FSMolTaskSampleEvalResults(size=141, acc=0.4326241134751773, balanced_acc=0.43795326349717967, f1=0.5, prec=0.43478260869565216, recall=0.5882352941176471, roc_auc=0.4443996776792909, avg_precision=0.45473942449914295, kappa=-0.1226114649681529, task_name='CHEMBL2219270', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48226950354609927)],\n",
       " 'CHEMBL2219189': [FSMolTaskSampleEvalResults(size=141, acc=0.5390070921985816, balanced_acc=0.5393360160965794, f1=0.5578231292517006, prec=0.5324675324675324, recall=0.5857142857142857, roc_auc=0.552112676056338, avg_precision=0.5698679066467551, kappa=0.07861666834221381, task_name='CHEMBL2219189', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219286': [FSMolTaskSampleEvalResults(size=141, acc=0.6382978723404256, balanced_acc=0.6352657004830918, f1=0.5714285714285715, prec=0.68, recall=0.4927536231884058, roc_auc=0.6861916264090178, avg_precision=0.6336623037304464, kappa=0.27209231703613723, task_name='CHEMBL2219286', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48936170212765956)],\n",
       " 'CHEMBL2219358': [FSMolTaskSampleEvalResults(size=141, acc=0.5460992907801419, balanced_acc=0.5450704225352112, f1=0.4666666666666667, prec=0.56, recall=0.4, roc_auc=0.5509054325955735, avg_precision=0.5544655310842213, kappa=0.09032258064516119, task_name='CHEMBL2219358', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219191': [FSMolTaskSampleEvalResults(size=141, acc=0.5177304964539007, balanced_acc=0.5257575757575758, f1=0.5584415584415584, prec=0.48863636363636365, recall=0.6515151515151515, roc_auc=0.5149494949494949, avg_precision=0.4984130575215656, kappa=0.05050505050505061, task_name='CHEMBL2219191', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.46808510638297873)],\n",
       " 'CHEMBL2219375': [FSMolTaskSampleEvalResults(size=141, acc=0.46099290780141844, balanced_acc=0.46678743961352653, f1=0.5730337078651685, prec=0.46788990825688076, recall=0.7391304347826086, roc_auc=0.4675925925925926, avg_precision=0.4694594374746175, kappa=-0.0656324582338903, task_name='CHEMBL2219375', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48936170212765956)],\n",
       " 'CHEMBL2219305': [FSMolTaskSampleEvalResults(size=141, acc=0.5886524822695035, balanced_acc=0.5836019339242546, f1=0.5084745762711865, prec=0.6, recall=0.4411764705882353, roc_auc=0.5979049153908138, avg_precision=0.5457510528877206, kappa=0.1687334824151251, task_name='CHEMBL2219305', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48226950354609927)],\n",
       " 'CHEMBL2219208': [FSMolTaskSampleEvalResults(size=141, acc=0.6170212765957447, balanced_acc=0.6203106091165793, f1=0.6301369863013699, prec=0.5822784810126582, recall=0.6865671641791045, roc_auc=0.6159741831383623, avg_precision=0.6023083051413674, kappa=0.23860000000000003, task_name='CHEMBL2219208', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.475177304964539)],\n",
       " 'CHEMBL2219340': [FSMolTaskSampleEvalResults(size=141, acc=0.524822695035461, balanced_acc=0.5259661835748792, f1=0.54421768707483, prec=0.5128205128205128, recall=0.5797101449275363, roc_auc=0.5185185185185185, avg_precision=0.4977033552076, kappa=0.05179162902740142, task_name='CHEMBL2219340', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48936170212765956)],\n",
       " 'CHEMBL2219399': [FSMolTaskSampleEvalResults(size=141, acc=0.5319148936170213, balanced_acc=0.5109090909090909, f1=0.26666666666666666, prec=0.5, recall=0.18181818181818182, roc_auc=0.5432323232323233, avg_precision=0.5270748468790616, kappa=0.022684310018903697, task_name='CHEMBL2219399', seed=0, num_train=16, num_test=141, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.46808510638297873)],\n",
       " 'CHEMBL2219211': [FSMolTaskSampleEvalResults(size=141, acc=0.5319148936170213, balanced_acc=0.5358581788879936, f1=0.5714285714285715, prec=0.5116279069767442, recall=0.6470588235294118, roc_auc=0.5539887187751813, avg_precision=0.5732555098447926, kappa=0.0710720702735077, task_name='CHEMBL2219211', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48226950354609927)],\n",
       " 'CHEMBL2354305': [FSMolTaskSampleEvalResults(size=158, acc=0.5063291139240507, balanced_acc=0.5063291139240507, f1=0.5894736842105263, prec=0.5045045045045045, recall=0.7088607594936709, roc_auc=0.49431180900496713, avg_precision=0.5074419693621224, kappa=0.012658227848101222, task_name='CHEMBL2354305', seed=0, num_train=16, num_test=158, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL2219355': [FSMolTaskSampleEvalResults(size=141, acc=0.5815602836879432, balanced_acc=0.5785024154589372, f1=0.5042016806722689, prec=0.6, recall=0.43478260869565216, roc_auc=0.5700483091787439, avg_precision=0.6056591807188667, kappa=0.15791071970847248, task_name='CHEMBL2219355', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48936170212765956)],\n",
       " 'CHEMBL2219242': [FSMolTaskSampleEvalResults(size=141, acc=0.5390070921985816, balanced_acc=0.5348101265822784, f1=0.4881889763779527, prec=0.47692307692307695, recall=0.5, roc_auc=0.5892200898325847, avg_precision=0.5333822729393054, kappa=0.06925967299685187, task_name='CHEMBL2219242', seed=0, num_train=16, num_test=141, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.4397163120567376)],\n",
       " 'CHEMBL2219366': [FSMolTaskSampleEvalResults(size=141, acc=0.5177304964539007, balanced_acc=0.5181086519114688, f1=0.5405405405405405, prec=0.5128205128205128, recall=0.5714285714285714, roc_auc=0.5740442655935614, avg_precision=0.5202553795414515, kappa=0.03618817852834755, task_name='CHEMBL2219366', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL3431930': [FSMolTaskSampleEvalResults(size=458, acc=0.8209606986899564, balanced_acc=0.8209606986899564, f1=0.8101851851851852, prec=0.8620689655172413, recall=0.7641921397379913, roc_auc=0.8383898095002003, avg_precision=0.8363280870785882, kappa=0.6419213973799127, task_name='CHEMBL3431930', seed=0, num_train=16, num_test=458, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL2219244': [FSMolTaskSampleEvalResults(size=141, acc=0.5531914893617021, balanced_acc=0.5543478260869565, f1=0.5714285714285715, prec=0.5384615384615384, recall=0.6086956521739131, roc_auc=0.539049919484702, avg_precision=0.4929573956830636, kappa=0.10840108401084014, task_name='CHEMBL2219244', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48936170212765956)],\n",
       " 'CHEMBL3705469': [FSMolTaskSampleEvalResults(size=139, acc=0.49640287769784175, balanced_acc=0.5, f1=0.6634615384615384, prec=0.49640287769784175, recall=1.0, roc_auc=0.425879917184265, avg_precision=0.4272611662089251, kappa=0.0, task_name='CHEMBL3705469', seed=0, num_train=16, num_test=139, fraction_pos_train=0.5, fraction_pos_test=0.49640287769784175)],\n",
       " 'CHEMBL2219389': [FSMolTaskSampleEvalResults(size=141, acc=0.5673758865248227, balanced_acc=0.5683098591549296, f1=0.6163522012578616, prec=0.550561797752809, recall=0.7, roc_auc=0.5901408450704226, avg_precision=0.574606781367938, kappa=0.13635907219600363, task_name='CHEMBL2219389', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL2219274': [FSMolTaskSampleEvalResults(size=141, acc=0.5815602836879432, balanced_acc=0.5818236714975845, f1=0.5815602836879432, prec=0.5694444444444444, recall=0.5942028985507246, roc_auc=0.6129227053140097, avg_precision=0.6421907352837745, kappa=0.16349924585218711, task_name='CHEMBL2219274', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48936170212765956)],\n",
       " 'CHEMBL2219408': [FSMolTaskSampleEvalResults(size=141, acc=0.5177304964539007, balanced_acc=0.533030303030303, f1=0.6, prec=0.49038461538461536, recall=0.7727272727272727, roc_auc=0.54, avg_precision=0.5067069252346093, kappa=0.0638547158758056, task_name='CHEMBL2219408', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.46808510638297873)],\n",
       " 'CHEMBL3706128': [FSMolTaskSampleEvalResults(size=201, acc=0.6368159203980099, balanced_acc=0.6305785123966943, f1=0.5680473372781064, prec=0.5393258426966292, recall=0.6, roc_auc=0.6721590909090909, avg_precision=0.5826638143803773, kappa=0.25627249227026205, task_name='CHEMBL3706128', seed=0, num_train=16, num_test=201, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.39800995024875624)],\n",
       " 'CHEMBL2219283': [FSMolTaskSampleEvalResults(size=141, acc=0.46099290780141844, balanced_acc=0.4451515151515152, f1=0.2549019607843137, prec=0.3611111111111111, recall=0.19696969696969696, roc_auc=0.42848484848484847, avg_precision=0.4251899450509883, kappa=-0.1127725856697821, task_name='CHEMBL2219283', seed=0, num_train=16, num_test=141, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.46808510638297873)],\n",
       " 'CHEMBL3707783': [FSMolTaskSampleEvalResults(size=146, acc=0.547945205479452, balanced_acc=0.547945205479452, f1=0.3888888888888889, prec=0.6, recall=0.2876712328767123, roc_auc=0.6387689998123476, avg_precision=0.6136843253385743, kappa=0.09589041095890416, task_name='CHEMBL3707783', seed=0, num_train=16, num_test=146, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL3214944': [FSMolTaskSampleEvalResults(size=562, acc=0.6067615658362989, balanced_acc=0.6074088145896657, f1=0.6666666666666667, prec=0.577023498694517, recall=0.7892857142857143, roc_auc=0.5979229989868288, avg_precision=0.5503694427940379, kappa=0.2145377736741586, task_name='CHEMBL3214944', seed=0, num_train=16, num_test=562, fraction_pos_train=0.5, fraction_pos_test=0.498220640569395)],\n",
       " 'CHEMBL2219334': [FSMolTaskSampleEvalResults(size=141, acc=0.5177304964539007, balanced_acc=0.5221595487510072, f1=0.5641025641025642, prec=0.5, recall=0.6470588235294118, roc_auc=0.48751007252215955, avg_precision=0.47575574664045084, kappa=0.043877143996808865, task_name='CHEMBL2219334', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.48226950354609927)],\n",
       " 'CHEMBL3705334': [FSMolTaskSampleEvalResults(size=127, acc=0.5748031496062992, balanced_acc=0.5740327380952381, f1=0.5263157894736842, prec=0.5882352941176471, recall=0.47619047619047616, roc_auc=0.6258680555555556, avg_precision=0.5789645613002212, kappa=0.14828614008941865, task_name='CHEMBL3705334', seed=0, num_train=16, num_test=127, fraction_pos_train=0.5, fraction_pos_test=0.49606299212598426)],\n",
       " 'CHEMBL3887333': [FSMolTaskSampleEvalResults(size=490, acc=0.7408163265306122, balanced_acc=0.7408163265306122, f1=0.7315010570824524, prec=0.7587719298245614, recall=0.7061224489795919, roc_auc=0.8049146189087881, avg_precision=0.7741863086999898, kappa=0.4816326530612245, task_name='CHEMBL3887333', seed=0, num_train=16, num_test=490, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL2219335': [FSMolTaskSampleEvalResults(size=141, acc=0.5106382978723404, balanced_acc=0.509076240419524, f1=0.48120300751879697, prec=0.48484848484848486, recall=0.47761194029850745, roc_auc=0.5252117789431222, avg_precision=0.4970360169126428, kappa=0.01816530426884644, task_name='CHEMBL2219335', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.475177304964539)],\n",
       " 'CHEMBL3888461': [FSMolTaskSampleEvalResults(size=157, acc=0.5732484076433121, balanced_acc=0.5740019474196689, f1=0.6171428571428572, prec=0.5567010309278351, recall=0.6923076923076923, roc_auc=0.5417072379097695, avg_precision=0.5367433680188248, kappa=0.1477760674066273, task_name='CHEMBL3888461', seed=0, num_train=16, num_test=157, fraction_pos_train=0.5, fraction_pos_test=0.4968152866242038)],\n",
       " 'CHEMBL3705476': [FSMolTaskSampleEvalResults(size=648, acc=0.5740740740740741, balanced_acc=0.5740128602048107, f1=0.5646687697160884, prec=0.5755627009646302, recall=0.5541795665634675, roc_auc=0.5831436056203858, avg_precision=0.5612301992572208, kappa=0.14804264359822028, task_name='CHEMBL3705476', seed=0, num_train=16, num_test=648, fraction_pos_train=0.5, fraction_pos_test=0.4984567901234568)],\n",
       " 'CHEMBL2219359': [FSMolTaskSampleEvalResults(size=141, acc=0.5531914893617021, balanced_acc=0.5566760790641387, f1=0.5714285714285715, prec=0.525, recall=0.6268656716417911, roc_auc=0.509479628882614, avg_precision=0.4801190381483168, kappa=0.11232137503747375, task_name='CHEMBL2219359', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.475177304964539)],\n",
       " 'CHEMBL3707738': [FSMolTaskSampleEvalResults(size=130, acc=0.5923076923076923, balanced_acc=0.5949337121212122, f1=0.6490066225165564, prec=0.5632183908045977, recall=0.765625, roc_auc=0.5500710227272727, avg_precision=0.5098458481588828, kappa=0.18883918059806926, task_name='CHEMBL3707738', seed=0, num_train=16, num_test=130, fraction_pos_train=0.5, fraction_pos_test=0.49230769230769234)],\n",
       " 'CHEMBL4133035': [FSMolTaskSampleEvalResults(size=182, acc=0.510989010989011, balanced_acc=0.510989010989011, f1=0.5291005291005291, prec=0.5102040816326531, recall=0.5494505494505495, roc_auc=0.5185364086462988, avg_precision=0.5408495363479425, kappa=0.02197802197802201, task_name='CHEMBL4133035', seed=0, num_train=16, num_test=182, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL2219363': [FSMolTaskSampleEvalResults(size=141, acc=0.5106382978723404, balanced_acc=0.5113682092555332, f1=0.5548387096774193, prec=0.5058823529411764, recall=0.6142857142857143, roc_auc=0.4629778672032193, avg_precision=0.47650813436761563, kappa=0.02270215971873435, task_name='CHEMBL2219363', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.49645390070921985)],\n",
       " 'CHEMBL819742': [FSMolTaskSampleEvalResults(size=142, acc=0.5140845070422535, balanced_acc=0.5140845070422535, f1=0.42016806722689076, prec=0.5208333333333334, recall=0.352112676056338, roc_auc=0.5062487601666337, avg_precision=0.5085358172296639, kappa=0.028169014084507005, task_name='CHEMBL819742', seed=0, num_train=16, num_test=142, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL3887295': [FSMolTaskSampleEvalResults(size=223, acc=0.5829596412556054, balanced_acc=0.582810489060489, f1=0.5674418604651164, prec=0.5865384615384616, recall=0.5495495495495496, roc_auc=0.6222651222651222, avg_precision=0.6160394325143885, kappa=0.16566761877941827, task_name='CHEMBL3887295', seed=0, num_train=16, num_test=223, fraction_pos_train=0.5, fraction_pos_test=0.4977578475336323)],\n",
       " 'CHEMBL2219404': [FSMolTaskSampleEvalResults(size=141, acc=0.3971631205673759, balanced_acc=0.4016740621218233, f1=0.43708609271523174, prec=0.39285714285714285, recall=0.4925373134328358, roc_auc=0.3567970956030657, avg_precision=0.38528480439406176, kappa=-0.1943198804185351, task_name='CHEMBL2219404', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.475177304964539)],\n",
       " 'CHEMBL3888181': [FSMolTaskSampleEvalResults(size=203, acc=0.541871921182266, balanced_acc=0.5417394680644535, f1=0.5279187817258884, prec=0.5416666666666666, recall=0.5148514851485149, roc_auc=0.5193166375461076, avg_precision=0.5022834998315355, kappa=0.08349919899024216, task_name='CHEMBL3888181', seed=0, num_train=16, num_test=203, fraction_pos_train=0.5, fraction_pos_test=0.4975369458128079)],\n",
       " 'CHEMBL924949': [FSMolTaskSampleEvalResults(size=126, acc=0.7142857142857143, balanced_acc=0.7116935483870968, f1=0.6538461538461537, prec=0.8095238095238095, recall=0.5483870967741935, roc_auc=0.8374495967741935, avg_precision=0.8466120039209197, kappa=0.4255319148936171, task_name='CHEMBL924949', seed=0, num_train=16, num_test=126, fraction_pos_train=0.5, fraction_pos_test=0.49206349206349204)],\n",
       " 'CHEMBL2219407': [FSMolTaskSampleEvalResults(size=141, acc=0.5602836879432624, balanced_acc=0.562726906010488, f1=0.5694444444444444, prec=0.5324675324675324, recall=0.6119402985074627, roc_auc=0.590560709963695, avg_precision=0.5609379186918203, kappa=0.12457440416583221, task_name='CHEMBL2219407', seed=0, num_train=16, num_test=141, fraction_pos_train=0.5, fraction_pos_test=0.475177304964539)],\n",
       " 'CHEMBL4005586': [FSMolTaskSampleEvalResults(size=232, acc=0.5689655172413793, balanced_acc=0.5689334819769603, f1=0.5652173913043478, prec=0.5652173913043478, recall=0.5652173913043478, roc_auc=0.5205128205128204, avg_precision=0.5196808694426485, kappa=0.1378669639539205, task_name='CHEMBL4005586', seed=0, num_train=16, num_test=232, fraction_pos_train=0.5, fraction_pos_test=0.4956896551724138)],\n",
       " 'CHEMBL3431932': [FSMolTaskSampleEvalResults(size=443, acc=0.6297968397291196, balanced_acc=0.6298968651909829, f1=0.645021645021645, prec=0.6182572614107884, recall=0.6742081447963801, roc_auc=0.6644653703477232, avg_precision=0.6161305446766601, kappa=0.259740789044669, task_name='CHEMBL3431932', seed=0, num_train=16, num_test=443, fraction_pos_train=0.5, fraction_pos_test=0.49887133182844245)],\n",
       " 'CHEMBL663407': [FSMolTaskSampleEvalResults(size=124, acc=0.6451612903225806, balanced_acc=0.6451612903225806, f1=0.6451612903225806, prec=0.6451612903225806, recall=0.6451612903225806, roc_auc=0.6823621227887617, avg_precision=0.7083956209737096, kappa=0.29032258064516125, task_name='CHEMBL663407', seed=0, num_train=16, num_test=124, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL3431933': [FSMolTaskSampleEvalResults(size=460, acc=0.48043478260869565, balanced_acc=0.48043478260869565, f1=0.6362252663622526, prec=0.4894613583138173, recall=0.908695652173913, roc_auc=0.4657750472589792, avg_precision=0.4683584030038308, kappa=-0.03913043478260869, task_name='CHEMBL3431933', seed=0, num_train=16, num_test=460, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL915809': [FSMolTaskSampleEvalResults(size=139, acc=0.6690647482014388, balanced_acc=0.661122661122661, f1=0.6034482758620688, prec=0.6862745098039216, recall=0.5384615384615384, roc_auc=0.6513513513513514, avg_precision=0.6329532312546615, kappa=0.326522013903518, task_name='CHEMBL915809', seed=0, num_train=16, num_test=139, fraction_pos_train=0.4166666666666667, fraction_pos_test=0.4676258992805755)],\n",
       " 'CHEMBL3706356': [FSMolTaskSampleEvalResults(size=277, acc=0.5884476534296029, balanced_acc=0.5890418100302367, f1=0.6459627329192545, prec=0.5652173913043478, recall=0.7536231884057971, roc_auc=0.6071056198519446, avg_precision=0.571126774341311, kappa=0.17787034626399378, task_name='CHEMBL3706356', seed=0, num_train=16, num_test=277, fraction_pos_train=0.5, fraction_pos_test=0.4981949458483754)],\n",
       " 'CHEMBL3707557': [FSMolTaskSampleEvalResults(size=124, acc=0.4838709677419355, balanced_acc=0.4838709677419355, f1=0.5294117647058824, prec=0.4864864864864865, recall=0.5806451612903226, roc_auc=0.5245837669094693, avg_precision=0.4995318326395604, kappa=-0.032258064516129004, task_name='CHEMBL3707557', seed=0, num_train=16, num_test=124, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL3887334': [FSMolTaskSampleEvalResults(size=210, acc=0.5571428571428572, balanced_acc=0.5571428571428572, f1=0.6008583690987125, prec=0.546875, recall=0.6666666666666666, roc_auc=0.563718820861678, avg_precision=0.5688208038551842, kappa=0.11428571428571432, task_name='CHEMBL3887334', seed=0, num_train=16, num_test=210, fraction_pos_train=0.5, fraction_pos_test=0.5)],\n",
       " 'CHEMBL3887759': [FSMolTaskSampleEvalResults(size=431, acc=0.46867749419953597, balanced_acc=0.46829242032730406, f1=0.362116991643454, prec=0.4513888888888889, recall=0.3023255813953488, roc_auc=0.46395348837209305, avg_precision=0.47679278802061464, kappa=-0.06346367270415576, task_name='CHEMBL3887759', seed=0, num_train=16, num_test=431, fraction_pos_train=0.5, fraction_pos_test=0.4988399071925754)],\n",
       " 'CHEMBL641707': [FSMolTaskSampleEvalResults(size=148, acc=0.6959459459459459, balanced_acc=0.6862228776069096, f1=0.5794392523364487, prec=0.5166666666666667, recall=0.6595744680851063, roc_auc=0.7143459026753739, avg_precision=0.47156055682274955, kappa=0.3468026677128285, task_name='CHEMBL641707', seed=0, num_train=16, num_test=148, fraction_pos_train=0.3333333333333333, fraction_pos_test=0.31756756756756754)],\n",
       " 'CHEMBL657032': [FSMolTaskSampleEvalResults(size=139, acc=0.4460431654676259, balanced_acc=0.4458592132505176, f1=0.42962962962962964, prec=0.4393939393939394, recall=0.42028985507246375, roc_auc=0.3057971014492754, avg_precision=0.3869701002164829, kappa=-0.10831521176348757, task_name='CHEMBL657032', seed=0, num_train=16, num_test=139, fraction_pos_train=0.5, fraction_pos_test=0.49640287769784175)]}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('fsmol-env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "interpreter": {
   "hash": "91c2cdb63b030871da94aa046e171a8c212268d3e9d71e3496f8c89eaedb0da0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}