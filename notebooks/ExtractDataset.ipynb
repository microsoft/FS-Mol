{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assembling a Few-Shot Learning Dataset of Molecules from ChEMBL\n",
    "\n",
    "Here we describe the procedure used to extract the final dataset. The final dataset was obtained through implementation of four key steps: \n",
    "\n",
    "1. Query ChEMBL to obtain initial raw data\n",
    "2. Clean the data to ensure good quality, and threshold to derive binary classification labels\n",
    "3. Selection of assays for use in the pretraining, vs. those selected as few-shot testing tasks and for validation.\n",
    "4. Featurization of the data to prepare suitable input to a range of models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "Extracting the dataset requires access to a MySQL database server holding the ChEMBL dataset. You can download the data and find instructions on setting this up on https://chembl.gitbook.io/chembl-interface-documentation/downloads.\n",
    "You will then need to update `fs_mol/preprocessing/utils/config.ini` with the connection information about your MySQL server.\n",
    "\n",
    "```python\n",
    "[mysql]\n",
    "host = # host \n",
    "database = # database name \n",
    "user = # username\n",
    "password = # password \n",
    "```\n",
    "\n",
    "Finally, we need to set up a few small bits to run this notebook successfully:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# This should be the location of the checkout of the FS-Mol repository:\n",
    "FS_MOL_CHECKOUT_PATH = os.path.join(os.environ['HOME'], \"Projects\", \"FS-Mol\")\n",
    "# This should be the where the result of the data extraction will be stored, requiring roughly TODO of space\n",
    "FS_MOL_RESULT_PATH = \"/tmp/fs_mol\"\n",
    "\n",
    "os.chdir(FS_MOL_CHECKOUT_PATH)\n",
    "sys.path.insert(0, FS_MOL_CHECKOUT_PATH)\n",
    "os.makedirs(FS_MOL_RESULT_PATH, exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Querying ChEMBL\n",
    "\n",
    "We query a SQL instance of the full ChEMBL database to obtain the raw data.\n",
    "This is implemented by the script `fs_mol/preprocessing/query.py`, which takes a list of candidate assays that should be considered (the one we used for the dataset released is stored in `fs_mol/preprocessing/utils/helper_files/assays.jsonl` and is read in as default if an alternative is not passed), and creates one `.csv` file for each assay using a range of fields detailed in `fs_mol/preprocessing/utils/queries.py`.\n",
    "\n",
    "We take a multiple option approach, as we recognise that not all entries in ChEMBL have complete protein target information. When no protein target information is available, the query is carried out for any other information that may be suitable for characterizing the assay such as the target cell type or tissue."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "! python fs_mol/preprocessing/query.py --save-dir {FS_MOL_RESULT_PATH}/raw_data --assay-list-file fs_mol/preprocessing/utils/helper_files/assays.jsonl"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a result of this raw data extraction, we obtained 36,093 separate raw assay files as `.csv`s, from a list of 36,160. Not all initially identified assays are able to return fields for any query option."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(os.path.join(FS_MOL_CHECKOUT_PATH, \"fs_mol/preprocessing/utils/helper_files/assays.jsonl\"), \"r\") as jf:\n",
    "    assays = json.load(jf)\n",
    "len(assays[\"assays\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Initial List of Assays\n",
    "Our initial query of ChEMBL selects only those assays that contain more than 32 datapoints. We accessed CHEMBL27 and selected all assays with more than 32 measurements. We record the assay ids and confidence scores, where confidence reflects the level of information about the target protein in the assay: '9' is a known single protein target, '0' is completely unknown, for instance it could be as broad as an entire tissue.\n",
    "\n",
    "To regenerate this list (after changing criteria, for example), you can run `fs_mol/preprocessing/initial_query.py`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "! python fs_mol/preprocessing/initial_query.py "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The script outputs the assay list to the default destination of `config.ini`'s `[initialquery]` section"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 2. Cleaning\n",
    "\n",
    "The cleaning procedure takes place in three keys stages, detailed in `fs_mol/preprocessing/clean.py`:\n",
    "\n",
    "1. Assays are selected to proceed to the next stage only if they reflect activity or inhibition measurements with units of \"%\", \"uM\" or \"nM\".\n",
    "2. SMILES are standardized, and XC50 (IC50 or EC50) measurements are converted to -log10([C]/NM) prior to thresholding. This step also de-duplicates measurements where applicable.\n",
    "3. A final (optional) thresholding step is applied."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Standardization\n",
    "\n",
    "The standardization procedure for SMILES is as follows: \n",
    "\n",
    "- Remove salts\n",
    "- Disconnect any metallo-organic complexes\n",
    "- Make certain the correct ion is present\n",
    "- Choose the largest fragment if the SMILES string represents disconnected components\n",
    "- Remove excess charges\n",
    "- Choose the canonical tautomer\n",
    "\n",
    "After this procedure, molecules are rejected if they have a molecular weight > 900 Da, and exact SMILES-value duplicate pairs are dropped within an assay. \n",
    "\n",
    "**De-duplication** of SMILES then accepts a degree of variation in the measured value for the same SMILES -- if a SMILES value is repeated in a dataframe, we accept measurements where the standard value measured is within the same order of magnitude, to fairly capture measurement noise. We reject all measurements for that SMILES if that is not the case. While this may reject stereoisomers with profoundly different chemical behaviors, we wish to remove erroneous measurements of other molecules. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Thresholding\n",
    "\n",
    "As part of cleaning the data, we automatically derive active/inactive labels from the activity data. Our thresholding proceeds via a automated procedure that attempts to adapt flexibly to each assay to ensure that we do not discount a number of measurements due to overly rigid thresholding rules. \n",
    "\n",
    "We take the median value of an assay's activity measurements, and use this as a threshold provided it is in the range 5 $\\le$ median(pXC) $\\le$ 7 for enzymes, or 4 $\\le$ median(pXC) $\\le$ 6 for all other assays. If the median is outside this range, we select PKX = 5.0 as our fixed threshold. \n",
    "\n",
    "With this threshold we are able to derive a binary activity label."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Overall, the cleaning can be applied to the extracted data as follows, the final directory will be \"cleaned\", but a custom suffix can be used."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "! python fs_mol/preprocessing/clean.py {FS_MOL_RESULT_PATH} --input-dir raw_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# 3. Assay Selection for train-valid-test split\n",
    "\n",
    "Our assay selection proceeds via examining the final sizes of the assays and their associated protein information. We begin with a list of 27004 assays for which cleaning did not result in removal of all data. Not all assays have available protein information. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv(os.path.join(FS_MOL_CHECKOUT_PATH, \"datasets/targets/target_info.csv\"))\n",
    "\n",
    "print(f\"We have {df.cleaned_size.sum()} measurements from our first pass of cleaning (cleaning_failed == False)\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.concat(\n",
    "    [\n",
    "        df.loc[df['target_id'].notna()].astype({\"target_id\": int}).astype({\"target_id\": str}),\n",
    "        df.loc[df['target_id'].isna()]\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# first select out assays that are very small\n",
    "df = df[df.cleaned_size>=32]\n",
    "print(f\"We have {len(df[df.target_id.notna()].target_id.unique())} unique known targets\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "EC numbers were assigned by additionally querying ChEMBL for the component and type synonyms from the component synonyms table. Where the type synonym was \"EC_number\" we are able to assign an EC number to the target. The `EC_super_class_name` is applied from a dictionary mapping from `EC_number`: \n",
    "```python\n",
    "EC_super_class_dict = {'1':'oxidoreductase',\n",
    "                       \"2\":'transferase',\n",
    "                       \"3\":'hydrolase',\n",
    "                       \"4\":'lyase',\n",
    "                       \"5\":'isomerase',\n",
    "                       \"6\":'ligase',\n",
    "                       \"7\":'translocase'}\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, there are a number of targets for which this classification is uncertain, and we wish to ensure that our final targets have a confident classification by EC class. The `protein_class_desc` is cleaned to define a `protein_family` and `protein_super_family`. `EC_name` is taken from the `component_synonym`. `reliable_target_EC` is `True` if only one EC number is present for the target (some have a list of conflicting values in the database), and `reliable_target_EC_super` is True if `EC_super_class` is single only. The same approach is taken for target protein descriptions: `reliable_target_protein_desc == True` reflects only single `protein_class_desc` entries (that is, non-type entries), `reliable_target_protein_super == True` is the same for `protein_super_family`.\n",
    "\n",
    "This information is included in our target info csvs for completeness. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To select test tasks, we require that they only have well known target ids, and since we also wish to categorise by EC number, we will select those for which a good EC number can be obtained. \n",
    "\n",
    "We first extract everything that cannot be included as a few-shot test task, which involves the cases of:\n",
    "- having no good EC number for the overall class (NaN or EC number super class considered unreliable -- `reliable_target_EC_super == False`). \n",
    "- no single target ID available (eg. non-single-protein measurements)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "possible_test = df[df.target_id.notna()]\n",
    "possible_test = possible_test[possible_test.reliable_target_EC_super.notna()]\n",
    "possible_test = possible_test[possible_test.reliable_target_EC_super == True]\n",
    "\n",
    "print(f\"Prior to filtering we have: {len(possible_test)} assays with well known EC super classes\")\n",
    "print(f\"This consists of {len(possible_test.target_id.unique())} targets with {possible_test.cleaned_size.sum()} individual measurement points.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We make further stringent requirements here on the test tasks: they must be less than 5000 datapoints to avoid high-throughput screens, as these are generally considered noisy and not in keeping with the QSAR data considered here. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best = possible_test.loc[\n",
    "    (possible_test[\"cleaned_size\"] >= 128) &\n",
    "    (possible_test[\"confidence\"] >= 8) &\n",
    "    (possible_test[\"percentage_pos\"] <= 70) &\n",
    "    (possible_test[\"percentage_pos\"] >= 30) &\n",
    "    (possible_test[\"cleaned_size\"] <= 5000)\n",
    "]\n",
    "\n",
    "print(f\"We have {len(set(possible_test.target_id.unique()))} possible test targets\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We would like 200 final few-shot tasks, but we may not be able to achieve this without impoverishing the training set. \n",
    "\n",
    "How many of each EC class would this represent, to maintain the current proportions in the data? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best.EC_super_class.value_counts() * 200/ best.EC_super_class.value_counts().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from collections import defaultdict\n",
    "required_target_numbers = {\"EC_super_class\": [str(x) for x in range(1, 8)], \"target_count\": [10, 150, 30, 3, 1, 3, 2]}\n",
    "ids = defaultdict(set)\n",
    "test_ids = set()\n",
    "for c, target_count in zip(required_target_numbers[\"EC_super_class\"],required_target_numbers[\"target_count\"]):\n",
    "    ids[c] = set(best[best.EC_super_class == c].target_id.value_counts().tail(target_count).index)\n",
    "    test_ids = test_ids.union(ids[c])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f\"We identify a total {len(test_ids)} that may be used in the testing set of tasks\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training set\n",
    "\n",
    "We can assemble the training set from all that remains now that we have selected our target protein IDs. It should be composed of all 'good' protein measurements with known targets and well known EC classes, as well as everything else where these values may be uncertain (for instance, the cases of non-enzymatic proteins where there is no such thing as an EC number).\n",
    "\n",
    "We then also remove non-protein target measurements (no target id), and suggest these are only to be used as part of an extended training set.\n",
    "\n",
    "We supply final tables of the train, valid and test set assays.\n",
    "\n",
    "We note that test assays are required to have a confidence score of 8 or 9, where this reflects a single protein target."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.read_csv(os.path.join(FS_MOL_CHECKOUT_PATH, \"datasets/targets/train_proteins.csv\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.read_csv(os.path.join(FS_MOL_CHECKOUT_PATH, \"datasets/targets/test_proteins.csv\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.read_csv(os.path.join(FS_MOL_CHECKOUT_PATH, \"datasets/targets/valid_proteins.csv\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In practice, the validation set chooses only those tasks for which EC super class is 2 as we want to reduce the time taken by validation steps, and note that majority of tasks in testing are associated with kinases."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Featurization\n",
    "\n",
    "In featurization we take the SMILES string (here termed 'canonical' following the careful cleaning) and use it to create rdkit mol objects, from which further featurization can proceed. This takes place in the `featurize.py`. \n",
    "\n",
    "The final featurized files include the SMILES string, but also the ECFP fingerprints, standard physico-chemical descriptors from rdkit, and a graph featurization. The graph featurization relies on `metadata.pkl.gz` as it is created by a set of featurizers with fixed vocabularies to maintain consistent featurization across all assays.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "! python fs_mol/preprocessing/featurize.py {FS_MOL_RESULT_PATH}/cleaned {FS_MOL_RESULT_PATH}/processed --balance-limits 30.0 70.0"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "364a84b153cebb70b247bbb5f574313c9ce336e4bd48a45ee6dc56a520a3d2e4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('fsmol': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}