{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the FSMol Dataset\n",
    "\n",
    "The `FSMolDataset` class provides access to the train/valid/test tasks of our few-shot learning dataset on molecules.\n",
    "\n",
    "An instance is created from the data directory by `FSMolDataset.from_directory(/path/to/dataset)`.\n",
    "The data in the `train`, `validation` and `test` folds of the dataset can be accessed using `FSMolDataset.get_task_reading_iterable`.\n",
    "By default, this method simply reads in the individual data files using a number of background worker processes and provides them in a standard format, but this behavior can be customized by providing a specialized callback function.\n",
    "The default implementation returns an iterable over `FSMolTask` objects, each containing an entire task's of single featurised molecules, `MoleculeDatapoint`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up local details:\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# This should be the location of the checkout of the FS-Mol repository:\n",
    "FS_MOL_CHECKOUT_PATH = os.path.join(os.environ['HOME'], \"Projects\", \"FS-Mol\")\n",
    "FS_MOL_DATASET_PATH = os.path.join(os.environ['HOME'], \"Datasets\", \"FS-Mol\")\n",
    "\n",
    "os.chdir(FS_MOL_CHECKOUT_PATH)\n",
    "sys.path.insert(0, FS_MOL_CHECKOUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Creating FSMolDataset and Accessing a Task\n",
    "\n",
    "First, we simply create a dataset and have a look at a single task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHEMBL1614202\n"
     ]
    }
   ],
   "source": [
    "from fs_mol.data import FSMolDataset, DataFold\n",
    "dataset = FSMolDataset.from_directory(FS_MOL_DATASET_PATH)\n",
    "\n",
    "valid_task_iterable = dataset.get_task_reading_iterable(DataFold.VALIDATION)\n",
    "task = next(iter(valid_task_iterable))\n",
    "print(task.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A task, by default, is simply a name and a list of datapoints, each stored as a `MoleculeDatapoint`, a dataclass with the following definition:\n",
    "\n",
    "```python\n",
    "@dataclass(frozen=True)\n",
    "class MoleculeDatapoint:\n",
    "    \"\"\"Data structure holding information for a single molecule.\n",
    "\n",
    "    Args:\n",
    "        task_name: String describing the task this datapoint is taken from.\n",
    "        smiles: SMILES string describing the molecule this datapoint corresponds to.\n",
    "        graph: GraphData object containing information about the molecule in graph representation\n",
    "            form, according to featurization chosen in preprocessing.\n",
    "        numeric_label: numerical label (e.g., activity), usually measured in the lab\n",
    "        bool_label: bool classification label, usually derived from the numeric label using a\n",
    "            threshold.\n",
    "        fingerprint: optional ECFP for the molecule.\n",
    "        descriptors: optional phys-chem descriptors for the molecule.\n",
    "    \"\"\"\n",
    "\n",
    "    task_name: str\n",
    "    smiles: str\n",
    "    graph: GraphData\n",
    "    numeric_label: float\n",
    "    bool_label: bool\n",
    "    fingerprint: Optional[np.ndarray]\n",
    "    descriptors: Optional[np.ndarray]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoleculeDatapoint(task_name='CHEMBL1614202', smiles='Cc1ccc(Cn2c(CCNC(=O)c3cccc(C)c3)nc3ccccc32)cc1', graph=GraphData(node_features=array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.]],\n",
       "      dtype=float32), adjacency_lists=[array([[ 0,  1],\n",
       "       [ 2,  3],\n",
       "       [ 4,  5],\n",
       "       [ 5,  6],\n",
       "       [ 6,  7],\n",
       "       [ 7,  8],\n",
       "       [ 8,  9],\n",
       "       [ 9, 10],\n",
       "       [10, 11],\n",
       "       [11, 13],\n",
       "       [14, 15],\n",
       "       [16, 17],\n",
       "       [17, 18],\n",
       "       [20, 21],\n",
       "       [22, 23],\n",
       "       [24, 25],\n",
       "       [ 4, 27],\n",
       "       [28,  1],\n",
       "       [26,  6],\n",
       "       [19, 13],\n",
       "       [26, 21]], dtype=int32), array([[ 1,  2],\n",
       "       [ 3,  4],\n",
       "       [11, 12],\n",
       "       [13, 14],\n",
       "       [15, 16],\n",
       "       [17, 19],\n",
       "       [ 7, 20],\n",
       "       [21, 22],\n",
       "       [23, 24],\n",
       "       [25, 26],\n",
       "       [27, 28]], dtype=int32), array([], shape=(0, 2), dtype=int32)], edge_features=[]), numeric_label=2818.4, bool_label=True, fingerprint=array([0, 0, 0, ..., 0, 0, 0], dtype=int32), descriptors=array([ 1.24287806e+01, -4.63928767e-02,  1.24287806e+01,  4.63928767e-02,\n",
       "        5.25716901e-01,  3.83494995e+02,  3.58295013e+02,  3.83199768e+02,\n",
       "        1.46000000e+02,  0.00000000e+00,  2.50800669e-01, -3.51586938e-01,\n",
       "        3.51586938e-01,  2.50800669e-01,  9.31034505e-01,  1.72413790e+00,\n",
       "        2.51724148e+00,  1.51829076e+00,  1.14242212e+03,  2.02169685e+01,\n",
       "        1.68521996e+01,  1.68521996e+01,  1.40973568e+01,  9.94552422e+00,\n",
       "        9.94552422e+00,  7.46386957e+00,  7.46386957e+00,  5.10932302e+00,\n",
       "        5.10932302e+00,  3.54493666e+00,  3.54493666e+00, -3.40000010e+00,\n",
       "        5.70256100e+06,  1.89399185e+01,  8.31202888e+00,  4.37343216e+00,\n",
       "        1.70767075e+02,  9.88388824e+00,  5.82440472e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  5.90717983e+00,  0.00000000e+00,  4.79453707e+00,\n",
       "        4.98397875e+00,  0.00000000e+00,  0.00000000e+00,  5.96578407e+01,\n",
       "        4.36763954e+01,  2.50737858e+01,  1.10334015e+01,  4.79453707e+00,\n",
       "        1.69405804e+01,  0.00000000e+00,  1.48678665e+01,  0.00000000e+00,\n",
       "        2.68130531e+01,  6.54475641e+00,  1.00874619e+02,  0.00000000e+00,\n",
       "        0.00000000e+00,  5.31678867e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  2.20030136e+01,  1.29655781e+01,  1.38474741e+01,\n",
       "        3.28727493e+01,  7.27964020e+01,  0.00000000e+00,  1.10334015e+01,\n",
       "        0.00000000e+00,  4.69199982e+01,  0.00000000e+00,  4.79453707e+00,\n",
       "        0.00000000e+00,  5.90717983e+00,  1.85290298e+01,  2.89660130e+01,\n",
       "        1.11269026e+01,  0.00000000e+00,  4.93883057e+01,  4.71394615e+01,\n",
       "        4.98397875e+00,  2.24883080e+00,  0.00000000e+00,  1.72505398e+01,\n",
       "        3.02528167e+00,  6.37086105e+00,  9.36308265e-01,  2.44251289e+01,\n",
       "        6.78667724e-01,  5.39771366e+00,  0.00000000e+00,  2.00000003e-01,\n",
       "        2.90000000e+01,  1.00000000e+00,  4.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  3.00000000e+00,  1.00000000e+00,\n",
       "        4.00000000e+00,  3.00000000e+00,  1.00000000e+00,  4.00000000e+00,\n",
       "        6.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        4.00000000e+00,  4.67394018e+00,  1.17230202e+02,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        2.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  1.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  2.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  3.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  2.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "      dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Making a Task Sample\n",
    "\n",
    "In practice, all methods require that we sample from the `FSMolTask`s, for example during evaluation.\n",
    "To this end, we have implemented a number of samplers, extensions of the `TaskSampler` abstract class, which provides a unified `sample` method.\n",
    "The baseline models implemented in this repository use stratified sampling (implemented in `StratifiedTaskSampler`), but `RandomTaskSampler` and `BalancedTaskSampler` exist as alternatives.\n",
    "\n",
    "In practice, sampling often requires additional parameters, such as a minimal support set size, a minimal query set size, or an upper desired query set size. When a task dataset cannot be sampled using these parameters (e.g., because it's too small), a `SamplingException` exception is thrown and the caller can decide how to handle this. For example, during training, it is often reasonable to simply ignore such exceptions and pass over failure cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fs_mol.data import StratifiedTaskSampler\n",
    "task_sampler = StratifiedTaskSampler(\n",
    "    train_size_or_ratio = 16,\n",
    "    valid_size_or_ratio = 0.0,\n",
    "    test_size_or_ratio = 256, \n",
    "    allow_smaller_test = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying a sampler returns a sample from the task, which contains a support/train set, validation set, and query/test set. In this case, the task is too small to return all requested testing samples, so it returns the maximum available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in task: 358\n",
      "Number of train samples: 16\n",
      "Number of test samples: 256\n",
      "Number of valid samples: 0\n"
     ]
    }
   ],
   "source": [
    "task_sample = task_sampler.sample(task, seed=0)\n",
    "\n",
    "print(f\"Number of samples in task: {len(task.samples)}\")\n",
    "print(f\"Number of train samples: {len(task_sample.train_samples)}\")\n",
    "print(f\"Number of test samples: {len(task_sample.test_samples)}\")\n",
    "print(f\"Number of valid samples: {len(task_sample.valid_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samplers are built such that using the same seed will always return the same data split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task sample, seed 0, first call  - First training SMILES O=C(CNC(=O)c1ccc(Cl)cc1)OC(C(=O)Nc1cc(C(F)(F)F)ccc1Cl)c1ccccc1\n",
      "Task sample, seed 0, second call - First training SMILES O=C(CNC(=O)c1ccc(Cl)cc1)OC(C(=O)Nc1cc(C(F)(F)F)ccc1Cl)c1ccccc1\n",
      "Task sample, seed 1, first call  - First training SMILES CNc1oc(C=Cc2cc(OC)c(OC)c(OC)c2)nc1C#N\n"
     ]
    }
   ],
   "source": [
    "task_sample_0 = task_sampler.sample(task, seed=0)\n",
    "task_sample_1 = task_sampler.sample(task, seed=1)\n",
    "\n",
    "print(f\"Task sample, seed 0, first call  - First training SMILES {task_sample.train_samples[0].smiles}\")\n",
    "print(f\"Task sample, seed 0, second call - First training SMILES {task_sample_0.train_samples[0].smiles}\")\n",
    "print(f\"Task sample, seed 1, first call  - First training SMILES {task_sample_1.train_samples[0].smiles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Custom Task Reading Functions in MAML\n",
    "\n",
    "When implementing models on top of FS-Mol, it is often useful to specialize the callback used in `get_task_reading_iterable`, for example to directly draw appropriate samples or do further featurization.\n",
    "\n",
    "In MAML, we for example need to use stratified samples in each training step:\n",
    "\n",
    "```python\n",
    "task_sampler = StratifiedTaskSampler(\n",
    "    train_size_or_ratio=train_size,\n",
    "    valid_size_or_ratio=0,\n",
    "    test_size_or_ratio=(min_test_size, test_size),\n",
    ")\n",
    "\n",
    "def read_and_sample_from_task(paths: List[RichPath], id: int) -> Iterable[FSMolTaskSample]:\n",
    "    for i, path in enumerate(paths):\n",
    "        task = FSMolTask.load_from_file(path)\n",
    "        yield task_sampler.sample(task, seed=id + i)\n",
    "\n",
    "train_task_samples = dataset.get_task_reading_iterable(\n",
    "    data_fold=DataFold.TRAIN, task_reader_fn=read_and_sample_from_task\n",
    ")\n",
    "```\n",
    "\n",
    "In this instance, `train_task_samples` will now be an `Iterable` of sampled tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching Task Samples\n",
    "\n",
    "The `fs_mol.data` package also provides infrastructure for minibatching, using the `FSMolBatcher` class.\n",
    "These are framework-agnostic, and are used both for TensorFlow (in our MAML baseline) and Torch (in our MAT and Multitask baselines).\n",
    "Concretely, an `FSMolBatcher` object can be used to turn a list of datapoints into a sequence of minibatches.\n",
    "Our graph models handle batches of graphs as a single graph in which the samples appear as disconnected components. This is already implemented by our default implementation of `FSMolBatcher`, and so consumers only need to provide thing extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: GNN Multitask Batching\n",
    "\n",
    "As example, consider the GNN Multitask model (see `fs_mol/data/multitask.py` for full code), which needs to include the task ID for each sample. To do this, we extend the `FSMolBatcher` class using the callback hooks for initializing, extending and finalizing a batch:\n",
    "\n",
    "```python\n",
    "def multitask_batcher_init_fn(batch_data: Dict[str, Any]):\n",
    "    batch_data[\"sample_to_task_id\"] = []\n",
    "\n",
    "def multitask_batcher_add_sample_fn(\n",
    "    batch_data: Dict[str, Any],\n",
    "    sample_id: int,\n",
    "    sample: MoleculeDatapoint,\n",
    "    task_name_to_id: Dict[str, int],\n",
    "):\n",
    "    batch_data[\"sample_to_task_id\"].append(task_name_to_id[sample.task_name])\n",
    "\n",
    "def multitask_batcher_finalizer_fn(\n",
    "    batch_data: Dict[str, Any]\n",
    ") -> Tuple[FSMolMultitaskBatch, np.ndarray]:\n",
    "    plain_batch = fsmol_batch_finalizer(batch_data)\n",
    "    return (\n",
    "        FSMolMultitaskBatch(\n",
    "            sample_to_task_id=np.stack(batch_data[\"sample_to_task_id\"], axis=0),\n",
    "            **dataclasses.asdict(plain_batch),\n",
    "        ),\n",
    "        np.stack(batch_data[\"bool_labels\"], axis=0),\n",
    "    )\n",
    "\n",
    "def get_multitask_batcher(\n",
    "    task_name_to_id: Dict[str, int],\n",
    "    max_num_graphs: Optional[int] = None,\n",
    "    max_num_nodes: Optional[int] = None,\n",
    "    max_num_edges: Optional[int] = None,\n",
    ") -> FSMolBatcher[FSMolMultitaskBatch, np.ndarray]:\n",
    "    return FSMolBatcher(\n",
    "        max_num_graphs=max_num_graphs,\n",
    "        max_num_nodes=max_num_nodes,\n",
    "        max_num_edges=max_num_edges,\n",
    "        init_callback=multitask_batcher_init_fn,\n",
    "        per_datapoint_callback=partial(\n",
    "            multitask_batcher_add_sample_fn, task_name_to_id=task_name_to_id\n",
    "        ),\n",
    "        finalizer_callback=multitask_batcher_finalizer_fn,\n",
    "    )\n",
    "```\n",
    "\n",
    "This batcher is then used to create batches of up to `num_chunked_tasks` loaded in parallel as follows:\n",
    "\n",
    "```python\n",
    "def paths_to_mixed_samples(\n",
    "    paths: List[RichPath], idx: int\n",
    ") -> Iterable[Tuple[FSMolMultitaskBatch, np.ndarray]]:\n",
    "    loaded_samples: List[MoleculeDatapoint] = []\n",
    "    for i, path in enumerate(paths):\n",
    "        task = FSMolTask.load_from_file(path)\n",
    "        task_sample = self._task_sampler.sample(task, seed=idx + i)\n",
    "        loaded_samples.extend(task_sample.train_samples)\n",
    "    if self._data_fold == DataFold.TRAIN:\n",
    "        np.random.shuffle(loaded_samples)\n",
    "\n",
    "    for features, labels in self._batcher.batch(loaded_samples):\n",
    "        yield features, labels\n",
    "\n",
    "task_iterable = self._dataset.get_task_reading_iterable(\n",
    "    data_fold=self._data_fold,\n",
    "    task_reader_fn=paths_to_mixed_samples,\n",
    "    reader_chunk_size=self._num_chunked_tasks,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: MAML Batching\n",
    "\n",
    "We can similarly use this from a Tensorflow model, namely our MAML implementation (see `fs_mol/data/maml.py`). Here, we created a `TFGraphBatchIterable` class that uses a `FSMolBatcher` using a customized `finalizer_callback` to produce a batch suitable for consumption in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'node_features': array([[0., 0., 0., ..., 1., 0., 0.],\n",
      "       [0., 1., 0., ..., 1., 0., 0.],\n",
      "       [0., 1., 0., ..., 1., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 1., 0., 0.],\n",
      "       [0., 1., 0., ..., 1., 0., 1.],\n",
      "       [0., 0., 1., ..., 1., 0., 1.]], dtype=float32), 'node_to_graph_map': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32), 'num_graphs_in_batch': 3, 'adjacency_list_0': array([[ 1,  2],\n",
      "       [ 2,  3],\n",
      "       [ 3,  4],\n",
      "       [ 4,  6],\n",
      "       [ 7,  8],\n",
      "       [ 9, 10],\n",
      "       [ 9, 11],\n",
      "       [ 1, 13],\n",
      "       [13, 14],\n",
      "       [14, 15],\n",
      "       [15, 17],\n",
      "       [17, 18],\n",
      "       [19, 20],\n",
      "       [20, 21],\n",
      "       [21, 22],\n",
      "       [21, 23],\n",
      "       [21, 24],\n",
      "       [25, 26],\n",
      "       [27, 28],\n",
      "       [14, 29],\n",
      "       [30, 31],\n",
      "       [32, 33],\n",
      "       [12,  6],\n",
      "       [27, 18],\n",
      "       [34, 29],\n",
      "       [36, 37],\n",
      "       [38, 39],\n",
      "       [39, 40],\n",
      "       [40, 41],\n",
      "       [42, 43],\n",
      "       [44, 45],\n",
      "       [40, 47],\n",
      "       [48, 49],\n",
      "       [50, 51],\n",
      "       [53, 54],\n",
      "       [54, 55],\n",
      "       [55, 56],\n",
      "       [57, 58],\n",
      "       [60, 37],\n",
      "       [46, 41],\n",
      "       [52, 47],\n",
      "       [59, 55],\n",
      "       [62, 63],\n",
      "       [64, 65],\n",
      "       [65, 66],\n",
      "       [66, 67],\n",
      "       [67, 68],\n",
      "       [68, 69],\n",
      "       [68, 70],\n",
      "       [71, 72],\n",
      "       [72, 73],\n",
      "       [73, 74],\n",
      "       [75, 76],\n",
      "       [76, 77],\n",
      "       [78, 79],\n",
      "       [79, 80],\n",
      "       [82, 63],\n",
      "       [81, 74]], dtype=int32), 'edge_features_0': array([], shape=(58, 0), dtype=float32), 'adjacency_list_1': array([[ 0,  1],\n",
      "       [ 4,  5],\n",
      "       [ 6,  7],\n",
      "       [ 8,  9],\n",
      "       [11, 12],\n",
      "       [15, 16],\n",
      "       [18, 19],\n",
      "       [20, 25],\n",
      "       [26, 27],\n",
      "       [29, 30],\n",
      "       [31, 32],\n",
      "       [33, 34],\n",
      "       [37, 38],\n",
      "       [41, 42],\n",
      "       [43, 44],\n",
      "       [45, 46],\n",
      "       [47, 48],\n",
      "       [49, 50],\n",
      "       [51, 52],\n",
      "       [39, 53],\n",
      "       [56, 57],\n",
      "       [58, 59],\n",
      "       [54, 60],\n",
      "       [63, 64],\n",
      "       [65, 71],\n",
      "       [74, 75],\n",
      "       [76, 78],\n",
      "       [79, 81],\n",
      "       [72, 82]], dtype=int32), 'edge_features_1': array([], shape=(29, 0), dtype=float32), 'adjacency_list_2': array([[35, 36],\n",
      "       [61, 62]], dtype=int32), 'edge_features_2': array([], shape=(2, 0), dtype=float32)}, {'target_value': array([0., 1., 1.], dtype=float32)})\n"
     ]
    }
   ],
   "source": [
    "from fs_mol.data.maml import TFGraphBatchIterable\n",
    "batched_data = TFGraphBatchIterable(\n",
    "    samples=task_sample.train_samples,\n",
    "    shuffle=True,\n",
    "    max_num_nodes=100,\n",
    ")\n",
    "\n",
    "print(next(iter(batched_data)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91c2cdb63b030871da94aa046e171a8c212268d3e9d71e3496f8c89eaedb0da0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('fsmol-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
